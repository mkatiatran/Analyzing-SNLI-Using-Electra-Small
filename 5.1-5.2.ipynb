{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 68671/68671 [1:42:32<00:00, 11.16it/s]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Wrong key type: '112' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(combined_data)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Create the oversampled training dataset\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m oversampled_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_oversampled_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Step 4: Fine-Tune the Model with the Oversampled Data\u001b[39;00m\n\u001b[1;32m     98\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     99\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m\n\u001b[1;32m    106\u001b[0m )\n",
      "Cell \u001b[0;32mIn[20], line 87\u001b[0m, in \u001b[0;36mcreate_oversampled_dataset\u001b[0;34m(dataset, hard_indices, duplication_factor)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_oversampled_dataset\u001b[39m(dataset, hard_indices, duplication_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Get the hard-to-learn examples\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     hard_examples \u001b[38;5;241m=\u001b[39m [\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m hard_indices]\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Duplicate each hard example by the duplication factor\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     oversampled_hard_examples \u001b[38;5;241m=\u001b[39m hard_examples \u001b[38;5;241m*\u001b[39m duplication_factor\n",
      "File \u001b[0;32m~/NLP/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2742\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:2727\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2725\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2726\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2727\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/NLP/venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:636\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m table\n\u001b[0;32m--> 636\u001b[0m query_type \u001b[38;5;241m=\u001b[39m \u001b[43mkey_to_query_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/NLP/venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:556\u001b[0m, in \u001b[0;36mkey_to_query_type\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mrange\u001b[39m, Iterable)):\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 556\u001b[0m \u001b[43m_raise_bad_key_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NLP/venv/lib/python3.12/site-packages/datasets/formatting/formatting.py:46\u001b[0m, in \u001b[0;36m_raise_bad_key_type\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_bad_key_type\u001b[39m(key: Any):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong key type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Expected one of int, slice, range, str or Iterable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Wrong key type: '112' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "dataset = load_dataset(\"snli\")\n",
    "checkpoint_folder = \"./New Folder With Items\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_folder)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_folder)\n",
    "\n",
    "# tokenize\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['premise'], batch['hypothesis'], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded_dataset = dataset.map(tokenize, batched=True)\n",
    "encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# filter out examples with `-1` labels\n",
    "encoded_dataset = encoded_dataset.filter(lambda example: example[\"labels\"] != -1)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {key: torch.stack([torch.tensor(item[key]) if not isinstance(item[key], torch.Tensor) else item[key]\n",
    "                              for item in batch])\n",
    "            for key in batch[0] if isinstance(batch[0][key], (int, float, list, torch.Tensor))}\n",
    "\n",
    "def get_data_loader(split, batch_size=8):\n",
    "    return DataLoader(encoded_dataset[split].with_format(\"torch\"), batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "# track predictions and confidence scores across multiple epochs\n",
    "def calculate_learning_dynamics(data_loader, model, num_epochs=3):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    confidences, correctness = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_confidences, epoch_correctness = [], []\n",
    "        \n",
    "        for batch in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                \n",
    "                # store confidence and correctness\n",
    "                max_probs, preds = torch.max(probs, dim=-1)\n",
    "                epoch_confidences.extend(max_probs.cpu().numpy())\n",
    "                epoch_correctness.extend((preds == batch[\"labels\"]).cpu().numpy())\n",
    "        \n",
    "        confidences.append(epoch_confidences)\n",
    "        correctness.append(epoch_correctness)\n",
    "    \n",
    "    return np.array(confidences), np.array(correctness)\n",
    "\n",
    "# get learning dynamics\n",
    "train_loader = get_data_loader(\"train\", batch_size=8)\n",
    "confidences, correctness = calculate_learning_dynamics(train_loader, model, num_epochs=1)\n",
    "\n",
    "# classify examples into easy, ambiguous, and hard-to-learn\n",
    "def classify_examples(confidences, correctness):\n",
    "    avg_confidence = confidences.mean(axis=0)\n",
    "    consistency = correctness.mean(axis=0)\n",
    "    \n",
    "    easy_indices = np.where((avg_confidence > 0.8) & (consistency == 1))[0]\n",
    "    hard_indices = np.where((avg_confidence < 0.5) & (consistency < 0.5))[0]\n",
    "    ambiguous_indices = np.where((avg_confidence >= 0.5) & (avg_confidence <= 0.8) & (consistency < 1))[0]\n",
    "    \n",
    "    return easy_indices, ambiguous_indices, hard_indices\n",
    "\n",
    "easy_indices, ambiguous_indices, hard_indices = classify_examples(confidences, correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a424dca735f641569d9f5c89480f04dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3767, 'grad_norm': 0.25721991062164307, 'learning_rate': 4.963868655335877e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3737, 'grad_norm': 32.28351974487305, 'learning_rate': 4.927737310671754e-05, 'epoch': 0.03}\n",
      "{'loss': 0.3743, 'grad_norm': 9.496427536010742, 'learning_rate': 4.8916059660076315e-05, 'epoch': 0.04}\n",
      "{'loss': 0.3721, 'grad_norm': 35.85519027709961, 'learning_rate': 4.855474621343508e-05, 'epoch': 0.06}\n",
      "{'loss': 0.3882, 'grad_norm': 12.20327377319336, 'learning_rate': 4.819343276679385e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3948, 'grad_norm': 20.38226890563965, 'learning_rate': 4.783211932015262e-05, 'epoch': 0.09}\n",
      "{'loss': 0.3815, 'grad_norm': 12.41571044921875, 'learning_rate': 4.7470805873511394e-05, 'epoch': 0.1}\n",
      "{'loss': 0.3973, 'grad_norm': 20.384620666503906, 'learning_rate': 4.710949242687016e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3772, 'grad_norm': 22.44713020324707, 'learning_rate': 4.6748178980228926e-05, 'epoch': 0.13}\n",
      "{'loss': 0.393, 'grad_norm': 14.110427856445312, 'learning_rate': 4.63868655335877e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4076, 'grad_norm': 2.1206021308898926, 'learning_rate': 4.602555208694647e-05, 'epoch': 0.16}\n",
      "{'loss': 0.3823, 'grad_norm': 17.920269012451172, 'learning_rate': 4.566423864030524e-05, 'epoch': 0.17}\n",
      "{'loss': 0.396, 'grad_norm': 6.4024152755737305, 'learning_rate': 4.530292519366401e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3899, 'grad_norm': 29.503215789794922, 'learning_rate': 4.494161174702278e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3923, 'grad_norm': 16.71930694580078, 'learning_rate': 4.458029830038155e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3913, 'grad_norm': 7.619138717651367, 'learning_rate': 4.421898485374032e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3963, 'grad_norm': 16.702192306518555, 'learning_rate': 4.385767140709909e-05, 'epoch': 0.25}\n",
      "{'loss': 0.379, 'grad_norm': 17.7139835357666, 'learning_rate': 4.349635796045786e-05, 'epoch': 0.26}\n",
      "{'loss': 0.4111, 'grad_norm': 4.781750202178955, 'learning_rate': 4.313504451381663e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4018, 'grad_norm': 8.979827880859375, 'learning_rate': 4.2773731067175396e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3981, 'grad_norm': 23.849470138549805, 'learning_rate': 4.241241762053417e-05, 'epoch': 0.3}\n",
      "{'loss': 0.386, 'grad_norm': 0.5312355756759644, 'learning_rate': 4.2051104173892936e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3974, 'grad_norm': 9.436087608337402, 'learning_rate': 4.168979072725171e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4073, 'grad_norm': 3.602031707763672, 'learning_rate': 4.1328477280610475e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3709, 'grad_norm': 0.9621033072471619, 'learning_rate': 4.096716383396925e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3883, 'grad_norm': 2.74212908744812, 'learning_rate': 4.0605850387328014e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4083, 'grad_norm': 28.734146118164062, 'learning_rate': 4.024453694068679e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3897, 'grad_norm': 18.16028594970703, 'learning_rate': 3.988322349404556e-05, 'epoch': 0.4}\n",
      "{'loss': 0.391, 'grad_norm': 11.463762283325195, 'learning_rate': 3.952191004740433e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3707, 'grad_norm': 25.362852096557617, 'learning_rate': 3.916059660076309e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3922, 'grad_norm': 29.608741760253906, 'learning_rate': 3.8799283154121866e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3742, 'grad_norm': 7.578509330749512, 'learning_rate': 3.843796970748064e-05, 'epoch': 0.46}\n",
      "{'loss': 0.3953, 'grad_norm': 14.962356567382812, 'learning_rate': 3.8076656260839406e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3732, 'grad_norm': 24.42331886291504, 'learning_rate': 3.771534281419817e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3856, 'grad_norm': 10.8734712600708, 'learning_rate': 3.7354029367556945e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3907, 'grad_norm': 16.436429977416992, 'learning_rate': 3.699271592091572e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3875, 'grad_norm': 12.94542407989502, 'learning_rate': 3.6631402474274484e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3818, 'grad_norm': 2.8064193725585938, 'learning_rate': 3.627008902763325e-05, 'epoch': 0.55}\n",
      "{'loss': 0.4024, 'grad_norm': 6.380703449249268, 'learning_rate': 3.5908775580992024e-05, 'epoch': 0.56}\n",
      "{'loss': 0.406, 'grad_norm': 3.2893733978271484, 'learning_rate': 3.55474621343508e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3751, 'grad_norm': 56.47527313232422, 'learning_rate': 3.518614868770956e-05, 'epoch': 0.59}\n",
      "{'loss': 0.4037, 'grad_norm': 28.778715133666992, 'learning_rate': 3.482483524106833e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3929, 'grad_norm': 18.211437225341797, 'learning_rate': 3.44635217944271e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3823, 'grad_norm': 20.89749526977539, 'learning_rate': 3.4102208347785876e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3923, 'grad_norm': 19.6571102142334, 'learning_rate': 3.374089490114464e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3943, 'grad_norm': 13.249005317687988, 'learning_rate': 3.337958145450341e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3764, 'grad_norm': 14.888724327087402, 'learning_rate': 3.301826800786218e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3973, 'grad_norm': 7.073553562164307, 'learning_rate': 3.2656954561220954e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4038, 'grad_norm': 19.326311111450195, 'learning_rate': 3.229564111457972e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3925, 'grad_norm': 8.962926864624023, 'learning_rate': 3.1934327667938494e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3859, 'grad_norm': 11.135663032531738, 'learning_rate': 3.157301422129726e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3779, 'grad_norm': 0.756117582321167, 'learning_rate': 3.121170077465603e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3778, 'grad_norm': 0.5933474898338318, 'learning_rate': 3.08503873280148e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3985, 'grad_norm': 25.225065231323242, 'learning_rate': 3.048907388137357e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4016, 'grad_norm': 0.7150687575340271, 'learning_rate': 3.012776043473234e-05, 'epoch': 0.79}\n",
      "{'loss': 0.3766, 'grad_norm': 17.372970581054688, 'learning_rate': 2.9766446988091112e-05, 'epoch': 0.81}\n",
      "{'loss': 0.4002, 'grad_norm': 14.144010543823242, 'learning_rate': 2.940513354144988e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3866, 'grad_norm': 19.16450309753418, 'learning_rate': 2.9043820094808648e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3753, 'grad_norm': 6.593926906585693, 'learning_rate': 2.8682506648167418e-05, 'epoch': 0.85}\n",
      "{'loss': 0.3978, 'grad_norm': 23.053539276123047, 'learning_rate': 2.832119320152619e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3829, 'grad_norm': 3.38503098487854, 'learning_rate': 2.795987975488496e-05, 'epoch': 0.88}\n",
      "{'loss': 0.403, 'grad_norm': 0.7066634297370911, 'learning_rate': 2.759856630824373e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4074, 'grad_norm': 7.37545919418335, 'learning_rate': 2.7237252861602496e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3629, 'grad_norm': 2.6766905784606934, 'learning_rate': 2.687593941496127e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3797, 'grad_norm': 14.166337966918945, 'learning_rate': 2.651462596832004e-05, 'epoch': 0.94}\n",
      "{'loss': 0.3702, 'grad_norm': 9.745753288269043, 'learning_rate': 2.615331252167881e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3728, 'grad_norm': 0.5912282466888428, 'learning_rate': 2.5791999075037575e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3837, 'grad_norm': 13.286858558654785, 'learning_rate': 2.543068562839635e-05, 'epoch': 0.98}\n",
      "{'loss': 0.4031, 'grad_norm': 0.7423560619354248, 'learning_rate': 2.5069372181755118e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c887b9a90714edeb98981e8b0318ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39658471941947937, 'eval_accuracy': 0.8834586466165414, 'eval_runtime': 51.7517, 'eval_samples_per_second': 190.177, 'eval_steps_per_second': 23.787, 'epoch': 1.0}\n",
      "{'loss': 0.3326, 'grad_norm': 6.218863487243652, 'learning_rate': 2.4708058735113888e-05, 'epoch': 1.01}\n",
      "{'loss': 0.354, 'grad_norm': 4.712692737579346, 'learning_rate': 2.4346745288472657e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3278, 'grad_norm': 37.56756591796875, 'learning_rate': 2.3985431841831427e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3546, 'grad_norm': 36.81509780883789, 'learning_rate': 2.3624118395190197e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3216, 'grad_norm': 20.366846084594727, 'learning_rate': 2.3262804948548966e-05, 'epoch': 1.07}\n",
      "{'loss': 0.3307, 'grad_norm': 0.9261724352836609, 'learning_rate': 2.2901491501907736e-05, 'epoch': 1.08}\n",
      "{'loss': 0.351, 'grad_norm': 15.74485969543457, 'learning_rate': 2.2540178055266506e-05, 'epoch': 1.1}\n",
      "{'loss': 0.3668, 'grad_norm': 39.46297073364258, 'learning_rate': 2.2178864608625275e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3317, 'grad_norm': 38.45446014404297, 'learning_rate': 2.1817551161984045e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3412, 'grad_norm': 0.42923691868782043, 'learning_rate': 2.1456237715342815e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3505, 'grad_norm': 6.570706367492676, 'learning_rate': 2.1094924268701584e-05, 'epoch': 1.16}\n",
      "{'loss': 0.3314, 'grad_norm': 18.405223846435547, 'learning_rate': 2.0733610822060354e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3487, 'grad_norm': 13.80798053741455, 'learning_rate': 2.0372297375419124e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3103, 'grad_norm': 62.89575958251953, 'learning_rate': 2.0010983928777894e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3322, 'grad_norm': 29.221820831298828, 'learning_rate': 1.9649670482136663e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3502, 'grad_norm': 0.9093045592308044, 'learning_rate': 1.9288357035495433e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3293, 'grad_norm': 0.4483298361301422, 'learning_rate': 1.8927043588854203e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3057, 'grad_norm': 0.28029727935791016, 'learning_rate': 1.8565730142212972e-05, 'epoch': 1.26}\n",
      "{'loss': 0.3182, 'grad_norm': 10.381178855895996, 'learning_rate': 1.8204416695571745e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3408, 'grad_norm': 8.470233917236328, 'learning_rate': 1.784310324893051e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3338, 'grad_norm': 70.9224853515625, 'learning_rate': 1.7481789802289285e-05, 'epoch': 1.3}\n",
      "{'loss': 0.3341, 'grad_norm': 66.02709197998047, 'learning_rate': 1.712047635564805e-05, 'epoch': 1.32}\n",
      "{'loss': 0.3363, 'grad_norm': 9.74285888671875, 'learning_rate': 1.6759162909006824e-05, 'epoch': 1.33}\n",
      "{'loss': 0.3352, 'grad_norm': 14.6093111038208, 'learning_rate': 1.639784946236559e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3423, 'grad_norm': 0.6519245505332947, 'learning_rate': 1.6036536015724364e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3641, 'grad_norm': 19.07367706298828, 'learning_rate': 1.567522256908313e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3136, 'grad_norm': 0.7120167016983032, 'learning_rate': 1.5313909122441903e-05, 'epoch': 1.39}\n",
      "{'loss': 0.347, 'grad_norm': 0.8961344361305237, 'learning_rate': 1.4952595675800671e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3423, 'grad_norm': 17.262588500976562, 'learning_rate': 1.4591282229159442e-05, 'epoch': 1.42}\n",
      "{'loss': 0.3133, 'grad_norm': 0.33776405453681946, 'learning_rate': 1.422996878251821e-05, 'epoch': 1.43}\n",
      "{'loss': 0.3174, 'grad_norm': 0.6625248789787292, 'learning_rate': 1.3868655335876982e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3459, 'grad_norm': 9.925521850585938, 'learning_rate': 1.350734188923575e-05, 'epoch': 1.46}\n",
      "{'loss': 0.332, 'grad_norm': 2.5359489917755127, 'learning_rate': 1.3146028442594521e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3207, 'grad_norm': 4.690032482147217, 'learning_rate': 1.2784714995953289e-05, 'epoch': 1.49}\n",
      "{'loss': 0.3268, 'grad_norm': 16.455583572387695, 'learning_rate': 1.2423401549312059e-05, 'epoch': 1.5}\n",
      "{'loss': 0.3658, 'grad_norm': 17.87740707397461, 'learning_rate': 1.206208810267083e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3244, 'grad_norm': 9.825011253356934, 'learning_rate': 1.17007746560296e-05, 'epoch': 1.53}\n",
      "{'loss': 0.3331, 'grad_norm': 17.703874588012695, 'learning_rate': 1.133946120938837e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3471, 'grad_norm': 0.9671311974525452, 'learning_rate': 1.097814776274714e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3282, 'grad_norm': 1.3415910005569458, 'learning_rate': 1.0616834316105909e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3078, 'grad_norm': 5.542919158935547, 'learning_rate': 1.0255520869464679e-05, 'epoch': 1.59}\n",
      "{'loss': 0.3114, 'grad_norm': 0.7867729067802429, 'learning_rate': 9.894207422823448e-06, 'epoch': 1.6}\n",
      "{'loss': 0.3235, 'grad_norm': 16.690881729125977, 'learning_rate': 9.532893976182218e-06, 'epoch': 1.62}\n",
      "{'loss': 0.3121, 'grad_norm': 18.239459991455078, 'learning_rate': 9.171580529540988e-06, 'epoch': 1.63}\n",
      "{'loss': 0.3329, 'grad_norm': 18.019243240356445, 'learning_rate': 8.810267082899757e-06, 'epoch': 1.65}\n",
      "{'loss': 0.2982, 'grad_norm': 0.7511322498321533, 'learning_rate': 8.448953636258527e-06, 'epoch': 1.66}\n",
      "{'loss': 0.3326, 'grad_norm': 51.208160400390625, 'learning_rate': 8.087640189617297e-06, 'epoch': 1.68}\n",
      "{'loss': 0.3123, 'grad_norm': 2.0144708156585693, 'learning_rate': 7.726326742976066e-06, 'epoch': 1.69}\n",
      "{'loss': 0.3339, 'grad_norm': 0.47804850339889526, 'learning_rate': 7.365013296334837e-06, 'epoch': 1.71}\n",
      "{'loss': 0.3245, 'grad_norm': 0.45179107785224915, 'learning_rate': 7.003699849693607e-06, 'epoch': 1.72}\n",
      "{'loss': 0.3477, 'grad_norm': 0.7871254086494446, 'learning_rate': 6.642386403052376e-06, 'epoch': 1.73}\n",
      "{'loss': 0.3236, 'grad_norm': 33.30666732788086, 'learning_rate': 6.281072956411147e-06, 'epoch': 1.75}\n",
      "{'loss': 0.3288, 'grad_norm': 5.837706089019775, 'learning_rate': 5.919759509769916e-06, 'epoch': 1.76}\n",
      "{'loss': 0.3264, 'grad_norm': 0.26062774658203125, 'learning_rate': 5.558446063128685e-06, 'epoch': 1.78}\n",
      "{'loss': 0.325, 'grad_norm': 4.200988292694092, 'learning_rate': 5.197132616487455e-06, 'epoch': 1.79}\n",
      "{'loss': 0.3107, 'grad_norm': 8.63161563873291, 'learning_rate': 4.835819169846225e-06, 'epoch': 1.81}\n",
      "{'loss': 0.328, 'grad_norm': 25.284954071044922, 'learning_rate': 4.4745057232049945e-06, 'epoch': 1.82}\n",
      "{'loss': 0.3233, 'grad_norm': 3.589339256286621, 'learning_rate': 4.113192276563765e-06, 'epoch': 1.84}\n",
      "{'loss': 0.3325, 'grad_norm': 43.86149597167969, 'learning_rate': 3.7518788299225347e-06, 'epoch': 1.85}\n",
      "{'loss': 0.324, 'grad_norm': 18.507190704345703, 'learning_rate': 3.3905653832813044e-06, 'epoch': 1.86}\n",
      "{'loss': 0.3113, 'grad_norm': 4.9756646156311035, 'learning_rate': 3.029251936640074e-06, 'epoch': 1.88}\n",
      "{'loss': 0.3218, 'grad_norm': 7.0786333084106445, 'learning_rate': 2.6679384899988438e-06, 'epoch': 1.89}\n",
      "{'loss': 0.3297, 'grad_norm': 20.598247528076172, 'learning_rate': 2.306625043357614e-06, 'epoch': 1.91}\n",
      "{'loss': 0.3125, 'grad_norm': 0.5261716842651367, 'learning_rate': 1.9453115967163836e-06, 'epoch': 1.92}\n",
      "{'loss': 0.3345, 'grad_norm': 0.5783023834228516, 'learning_rate': 1.5839981500751535e-06, 'epoch': 1.94}\n",
      "{'loss': 0.3326, 'grad_norm': 8.691044807434082, 'learning_rate': 1.2226847034339232e-06, 'epoch': 1.95}\n",
      "{'loss': 0.3395, 'grad_norm': 20.61199188232422, 'learning_rate': 8.613712567926929e-07, 'epoch': 1.97}\n",
      "{'loss': 0.3059, 'grad_norm': 0.20825453102588654, 'learning_rate': 5.000578101514627e-07, 'epoch': 1.98}\n",
      "{'loss': 0.2936, 'grad_norm': 25.298452377319336, 'learning_rate': 1.387443635102324e-07, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd0b2615eb4473a090d3e8a3f7ce11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44166556000709534, 'eval_accuracy': 0.8892501524080472, 'eval_runtime': 59.8171, 'eval_samples_per_second': 164.535, 'eval_steps_per_second': 20.579, 'epoch': 2.0}\n",
      "{'train_runtime': 13238.9109, 'train_samples_per_second': 41.811, 'train_steps_per_second': 5.226, 'train_loss': 0.35926475556878934, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7516c9d996c54f019833ec0afb9c0356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on the Validation Set: 0.8893\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def create_oversampled_dataset(dataset, hard_indices, duplication_factor=1, sample_fraction=0.5):\n",
    "   # sample a subset of all examples \n",
    "    total_examples = len(dataset)\n",
    "    sample_size = int(sample_fraction * total_examples)\n",
    "    all_examples_sample = random.sample([dataset[i] for i in range(total_examples)], sample_size)\n",
    "    \n",
    "   # get hard-to-learn examples\n",
    "    hard_examples = [dataset[int(i)] for i in hard_indices]\n",
    "   # duplicate each hard example by dupe factor\n",
    "    oversampled_hard_examples = hard_examples * duplication_factor\n",
    "    \n",
    "   # combine the sampled examples with oversampled hard examples\n",
    "    combined_data = all_examples_sample + oversampled_hard_examples\n",
    "    return Dataset.from_dict({k: [d[k] for d in combined_data] for k in combined_data[0]})\n",
    "\n",
    "oversampled_train_dataset = create_oversampled_dataset(encoded_dataset[\"train\"], hard_indices)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=oversampled_train_dataset,\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(f\"Final Accuracy on the Validation Set: {results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013e8be72b574f26ae8ab1bf85c6965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on the Test Set: 0.8881\n"
     ]
    }
   ],
   "source": [
    "test_dataset = encoded_dataset[\"test\"]\n",
    "\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(f\"Final accuracy on test: {test_results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 1 with 245774 examples for 2 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffeb315b9bdd43e48aecec52c55ad260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1901, 'grad_norm': 0.022779373452067375, 'learning_rate': 4.959312544756201e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1664, 'grad_norm': 0.22065651416778564, 'learning_rate': 4.918625089512402e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1653, 'grad_norm': 150.581787109375, 'learning_rate': 4.877937634268602e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1884, 'grad_norm': 0.08925431221723557, 'learning_rate': 4.837250179024803e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1884, 'grad_norm': 0.10277227312326431, 'learning_rate': 4.796562723781004e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1977, 'grad_norm': 60.49163055419922, 'learning_rate': 4.755875268537205e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1624, 'grad_norm': 65.51551055908203, 'learning_rate': 4.715187813293406e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1833, 'grad_norm': 0.14181557297706604, 'learning_rate': 4.674500358049607e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1914, 'grad_norm': 64.29419708251953, 'learning_rate': 4.633812902805807e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1763, 'grad_norm': 0.4182526767253876, 'learning_rate': 4.593125447562008e-05, 'epoch': 0.16}\n",
      "{'loss': 0.193, 'grad_norm': 0.050073109567165375, 'learning_rate': 4.552437992318209e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1874, 'grad_norm': 2.0731186866760254, 'learning_rate': 4.5117505370744095e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1799, 'grad_norm': 87.29896545410156, 'learning_rate': 4.47106308183061e-05, 'epoch': 0.21}\n",
      "{'loss': 0.1691, 'grad_norm': 0.12917004525661469, 'learning_rate': 4.4303756265868105e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1646, 'grad_norm': 0.08206047117710114, 'learning_rate': 4.389688171343011e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1913, 'grad_norm': 0.5596734881401062, 'learning_rate': 4.349000716099212e-05, 'epoch': 0.26}\n",
      "{'loss': 0.2176, 'grad_norm': 0.030728105455636978, 'learning_rate': 4.3083132608554136e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1998, 'grad_norm': 91.81611633300781, 'learning_rate': 4.2676258056116145e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1855, 'grad_norm': 6.883074760437012, 'learning_rate': 4.226938350367815e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1827, 'grad_norm': 0.2005654275417328, 'learning_rate': 4.1862508951240154e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2026, 'grad_norm': 2.7714052200317383, 'learning_rate': 4.145563439880216e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1846, 'grad_norm': 0.007581560872495174, 'learning_rate': 4.104875984636417e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1871, 'grad_norm': 0.14184530079364777, 'learning_rate': 4.064188529392618e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2079, 'grad_norm': 0.018740646541118622, 'learning_rate': 4.023501074148819e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1918, 'grad_norm': 0.0581955686211586, 'learning_rate': 3.982813618905019e-05, 'epoch': 0.41}\n",
      "{'loss': 0.1744, 'grad_norm': 0.17962703108787537, 'learning_rate': 3.94212616366122e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1891, 'grad_norm': 2.4478211402893066, 'learning_rate': 3.9014387084174206e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1862, 'grad_norm': 0.11407053470611572, 'learning_rate': 3.860751253173622e-05, 'epoch': 0.46}\n",
      "{'loss': 0.194, 'grad_norm': 0.34766560792922974, 'learning_rate': 3.820063797929823e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1884, 'grad_norm': 22.666833877563477, 'learning_rate': 3.779376342686024e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1821, 'grad_norm': 34.79754638671875, 'learning_rate': 3.738688887442224e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1851, 'grad_norm': 12.398835182189941, 'learning_rate': 3.698001432198425e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1978, 'grad_norm': 0.07272990047931671, 'learning_rate': 3.6573139769546255e-05, 'epoch': 0.54}\n",
      "{'loss': 0.1814, 'grad_norm': 0.17712293565273285, 'learning_rate': 3.6166265217108264e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1732, 'grad_norm': 0.1468650847673416, 'learning_rate': 3.575939066467027e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1906, 'grad_norm': 1.2011644840240479, 'learning_rate': 3.535251611223227e-05, 'epoch': 0.59}\n",
      "{'loss': 0.1499, 'grad_norm': 0.07819704711437225, 'learning_rate': 3.494564155979428e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1774, 'grad_norm': 0.0399303212761879, 'learning_rate': 3.453876700735629e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1659, 'grad_norm': 0.21414600312709808, 'learning_rate': 3.4131892454918305e-05, 'epoch': 0.63}\n",
      "{'loss': 0.1734, 'grad_norm': 0.2402435690164566, 'learning_rate': 3.372501790248031e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1752, 'grad_norm': 0.005259477533400059, 'learning_rate': 3.331814335004232e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1627, 'grad_norm': 2.3234148025512695, 'learning_rate': 3.291126879760432e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1911, 'grad_norm': 0.10547328740358353, 'learning_rate': 3.250439424516633e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1852, 'grad_norm': 0.2135530263185501, 'learning_rate': 3.209751969272834e-05, 'epoch': 0.72}\n",
      "{'loss': 0.1774, 'grad_norm': 107.17991638183594, 'learning_rate': 3.169064514029035e-05, 'epoch': 0.73}\n",
      "{'loss': 0.1828, 'grad_norm': 0.011827891692519188, 'learning_rate': 3.1283770587852356e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1746, 'grad_norm': 0.1554703414440155, 'learning_rate': 3.087689603541436e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1676, 'grad_norm': 0.011872154660522938, 'learning_rate': 3.047002148297637e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1714, 'grad_norm': 36.59164047241211, 'learning_rate': 3.0063146930538378e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1691, 'grad_norm': 0.1866438090801239, 'learning_rate': 2.9656272378100386e-05, 'epoch': 0.81}\n",
      "{'loss': 0.18, 'grad_norm': 1.9273521900177002, 'learning_rate': 2.9249397825662394e-05, 'epoch': 0.83}\n",
      "{'loss': 0.1821, 'grad_norm': 5.310713291168213, 'learning_rate': 2.8842523273224402e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1618, 'grad_norm': 0.3839961290359497, 'learning_rate': 2.8435648720786407e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1689, 'grad_norm': 0.3404649496078491, 'learning_rate': 2.8028774168348416e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1505, 'grad_norm': 0.020095590502023697, 'learning_rate': 2.7621899615910424e-05, 'epoch': 0.9}\n",
      "{'loss': 0.1768, 'grad_norm': 0.5176196098327637, 'learning_rate': 2.7215025063472432e-05, 'epoch': 0.91}\n",
      "{'loss': 0.189, 'grad_norm': 59.0877799987793, 'learning_rate': 2.680815051103444e-05, 'epoch': 0.93}\n",
      "{'loss': 0.156, 'grad_norm': 0.05077550560235977, 'learning_rate': 2.6401275958596445e-05, 'epoch': 0.94}\n",
      "{'loss': 0.1743, 'grad_norm': 6.753963947296143, 'learning_rate': 2.5994401406158454e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1606, 'grad_norm': 17.138538360595703, 'learning_rate': 2.5587526853720462e-05, 'epoch': 0.98}\n",
      "{'loss': 0.1587, 'grad_norm': 0.07543700188398361, 'learning_rate': 2.518065230128247e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9b83e1a09f47298f25ef8961a01b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6968719959259033, 'eval_accuracy': 0.8908758382442593, 'eval_runtime': 52.117, 'eval_samples_per_second': 188.844, 'eval_steps_per_second': 23.62, 'epoch': 1.0}\n",
      "{'loss': 0.1521, 'grad_norm': 0.041422486305236816, 'learning_rate': 2.4773777748844475e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1122, 'grad_norm': 0.03492776304483414, 'learning_rate': 2.4366903196406483e-05, 'epoch': 1.03}\n",
      "{'loss': 0.1026, 'grad_norm': 16.27977180480957, 'learning_rate': 2.3960028643968495e-05, 'epoch': 1.04}\n",
      "{'loss': 0.109, 'grad_norm': 0.11146517843008041, 'learning_rate': 2.35531540915305e-05, 'epoch': 1.06}\n",
      "{'loss': 0.1032, 'grad_norm': 103.19365692138672, 'learning_rate': 2.3146279539092508e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0938, 'grad_norm': 55.30762481689453, 'learning_rate': 2.2739404986654516e-05, 'epoch': 1.09}\n",
      "{'loss': 0.1208, 'grad_norm': 0.020430075004696846, 'learning_rate': 2.233253043421652e-05, 'epoch': 1.11}\n",
      "{'loss': 0.1103, 'grad_norm': 0.014562027528882027, 'learning_rate': 2.1925655881778533e-05, 'epoch': 1.12}\n",
      "{'loss': 0.1068, 'grad_norm': 0.037812914699316025, 'learning_rate': 2.151878132934054e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1147, 'grad_norm': 0.17104199528694153, 'learning_rate': 2.1111906776902546e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1054, 'grad_norm': 0.031971853226423264, 'learning_rate': 2.0705032224464554e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1077, 'grad_norm': 0.3887299597263336, 'learning_rate': 2.029815767202656e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0883, 'grad_norm': 0.0009495372651144862, 'learning_rate': 1.9891283119588568e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0972, 'grad_norm': 0.0015619322657585144, 'learning_rate': 1.948440856715058e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1019, 'grad_norm': 36.49704360961914, 'learning_rate': 1.9077534014712584e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1074, 'grad_norm': 0.005126260686665773, 'learning_rate': 1.8670659462274592e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1161, 'grad_norm': 11.651091575622559, 'learning_rate': 1.82637849098366e-05, 'epoch': 1.27}\n",
      "{'loss': 0.1065, 'grad_norm': 0.0961977019906044, 'learning_rate': 1.7856910357398606e-05, 'epoch': 1.29}\n",
      "{'loss': 0.08, 'grad_norm': 190.99850463867188, 'learning_rate': 1.7450035804960617e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0964, 'grad_norm': 0.33013200759887695, 'learning_rate': 1.7043161252522625e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0923, 'grad_norm': 0.02445012517273426, 'learning_rate': 1.663628670008463e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0836, 'grad_norm': 0.13832469284534454, 'learning_rate': 1.622941214764664e-05, 'epoch': 1.35}\n",
      "{'loss': 0.1004, 'grad_norm': 0.021134180948138237, 'learning_rate': 1.5822537595208644e-05, 'epoch': 1.37}\n",
      "{'loss': 0.088, 'grad_norm': 29.86609649658203, 'learning_rate': 1.5415663042770652e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1085, 'grad_norm': 0.056231968104839325, 'learning_rate': 1.5008788490332662e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1088, 'grad_norm': 0.018149366602301598, 'learning_rate': 1.4601913937894668e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0876, 'grad_norm': 48.95499801635742, 'learning_rate': 1.4195039385456677e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0928, 'grad_norm': 0.0007597754010930657, 'learning_rate': 1.3788164833018685e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1, 'grad_norm': 0.14416639506816864, 'learning_rate': 1.3381290280580691e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0944, 'grad_norm': 0.00256313756108284, 'learning_rate': 1.29744157281427e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0891, 'grad_norm': 0.11633283644914627, 'learning_rate': 1.2567541175704708e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0877, 'grad_norm': 0.0054223849438130856, 'learning_rate': 1.2160666623266715e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0867, 'grad_norm': 0.11879782378673553, 'learning_rate': 1.1753792070828723e-05, 'epoch': 1.53}\n",
      "{'loss': 0.105, 'grad_norm': 0.01772141642868519, 'learning_rate': 1.134691751839073e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0845, 'grad_norm': 0.0033885780721902847, 'learning_rate': 1.0940042965952738e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0895, 'grad_norm': 18.627307891845703, 'learning_rate': 1.0533168413514746e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0992, 'grad_norm': 0.01614316925406456, 'learning_rate': 1.0126293861076754e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0711, 'grad_norm': 0.3935677409172058, 'learning_rate': 9.719419308638761e-06, 'epoch': 1.61}\n",
      "{'loss': 0.1046, 'grad_norm': 0.21793042123317719, 'learning_rate': 9.312544756200767e-06, 'epoch': 1.63}\n",
      "{'loss': 0.0864, 'grad_norm': 20.6561222076416, 'learning_rate': 8.905670203762777e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0864, 'grad_norm': 0.049664322286844254, 'learning_rate': 8.498795651324784e-06, 'epoch': 1.66}\n",
      "{'loss': 0.079, 'grad_norm': 0.04834883660078049, 'learning_rate': 8.09192109888679e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0833, 'grad_norm': 0.009387805126607418, 'learning_rate': 7.685046546448799e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0818, 'grad_norm': 0.0013886158121749759, 'learning_rate': 7.278171994010807e-06, 'epoch': 1.71}\n",
      "{'loss': 0.0837, 'grad_norm': 0.0004709085915237665, 'learning_rate': 6.871297441572815e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0995, 'grad_norm': 0.9848231673240662, 'learning_rate': 6.464422889134822e-06, 'epoch': 1.74}\n",
      "{'loss': 0.0785, 'grad_norm': 0.01174107100814581, 'learning_rate': 6.0575483366968295e-06, 'epoch': 1.76}\n",
      "{'loss': 0.082, 'grad_norm': 0.003777220379561186, 'learning_rate': 5.650673784258838e-06, 'epoch': 1.77}\n",
      "{'loss': 0.0846, 'grad_norm': 0.008037722669541836, 'learning_rate': 5.243799231820845e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0521, 'grad_norm': 0.005638169590383768, 'learning_rate': 4.8369246793828535e-06, 'epoch': 1.81}\n",
      "{'loss': 0.0828, 'grad_norm': 0.00429835868999362, 'learning_rate': 4.43005012694486e-06, 'epoch': 1.82}\n",
      "{'loss': 0.0755, 'grad_norm': 0.09464739263057709, 'learning_rate': 4.023175574506868e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0781, 'grad_norm': 130.1771697998047, 'learning_rate': 3.6163010220688757e-06, 'epoch': 1.86}\n",
      "{'loss': 0.0859, 'grad_norm': 0.23621132969856262, 'learning_rate': 3.2094264696308836e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0773, 'grad_norm': 0.011567151173949242, 'learning_rate': 2.802551917192891e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0769, 'grad_norm': 0.0025917300954461098, 'learning_rate': 2.395677364754899e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0976, 'grad_norm': 140.60702514648438, 'learning_rate': 1.9888028123169063e-06, 'epoch': 1.92}\n",
      "{'loss': 0.081, 'grad_norm': 0.0007920715725049376, 'learning_rate': 1.5819282598789142e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0818, 'grad_norm': 0.0011524524306878448, 'learning_rate': 1.1750537074409218e-06, 'epoch': 1.95}\n",
      "{'loss': 0.0668, 'grad_norm': 0.12205258756875992, 'learning_rate': 7.681791550029296e-07, 'epoch': 1.97}\n",
      "{'loss': 0.0698, 'grad_norm': 37.317718505859375, 'learning_rate': 3.613046025649372e-07, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbd0551d154446f9b044a3472d4e3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8658453226089478, 'eval_accuracy': 0.8937207884576306, 'eval_runtime': 59.8275, 'eval_samples_per_second': 164.506, 'eval_steps_per_second': 20.576, 'epoch': 2.0}\n",
      "{'train_runtime': 12790.1592, 'train_samples_per_second': 38.432, 'train_steps_per_second': 4.804, 'train_loss': 0.13611223402607528, 'epoch': 2.0}\n",
      "Starting Phase 2 with 4705 examples for 2 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225ea4697a2b42c08c41b4eda94cd1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1396, 'grad_norm': 8.577925682067871, 'learning_rate': 2.8777589134125638e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0569aa33d4094079a8b749f3c50fecc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7110785841941833, 'eval_accuracy': 0.5989636252794147, 'eval_runtime': 55.0249, 'eval_samples_per_second': 178.864, 'eval_steps_per_second': 22.372, 'epoch': 1.0}\n",
      "{'loss': 0.8931, 'grad_norm': 18.122976303100586, 'learning_rate': 7.5551782682512745e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefdbc3103bf485098fa709708c89259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5401347875595093, 'eval_accuracy': 0.7590936801463117, 'eval_runtime': 51.562, 'eval_samples_per_second': 190.877, 'eval_steps_per_second': 23.874, 'epoch': 2.0}\n",
      "{'train_runtime': 335.4837, 'train_samples_per_second': 28.049, 'train_steps_per_second': 3.511, 'train_loss': 0.9913968278920509, 'epoch': 2.0}\n",
      "Starting Phase 3 with 1040 examples for 3 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc051bbb4db4845a2457e6c490a98dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444b330714d944488ac65d5ae55283e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6359837055206299, 'eval_accuracy': 0.7309489941068888, 'eval_runtime': 51.6632, 'eval_samples_per_second': 190.503, 'eval_steps_per_second': 23.827, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f56f987061b423298c1b693a5238311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.470461368560791, 'eval_accuracy': 0.8090835196098354, 'eval_runtime': 52.0351, 'eval_samples_per_second': 189.142, 'eval_steps_per_second': 23.657, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69b4cbbdec845d882a721414bb15481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47851526737213135, 'eval_accuracy': 0.8182280024385288, 'eval_runtime': 49.4559, 'eval_samples_per_second': 199.006, 'eval_steps_per_second': 24.891, 'epoch': 3.0}\n",
      "{'train_runtime': 227.5855, 'train_samples_per_second': 13.709, 'train_steps_per_second': 1.714, 'train_loss': 0.9826552953475561, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26150e1627c444eab63347efd3b515d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on the Validation Set: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# create subsets of the training dataset\n",
    "from torch.utils.data import Subset\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "easy_indices = list(easy_indices)\n",
    "ambiguous_indices = list(ambiguous_indices)\n",
    "hard_indices = list(hard_indices)\n",
    "\n",
    "# take 50% of each subset\n",
    "easy_dataset = Subset(encoded_dataset[\"train\"], random.sample(easy_indices, len(easy_indices) // 2))\n",
    "ambiguous_dataset = Subset(encoded_dataset[\"train\"], random.sample(ambiguous_indices, len(ambiguous_indices) // 2))\n",
    "hard_dataset = Subset(encoded_dataset[\"train\"], random.sample(hard_indices, len(hard_indices) // 2))\n",
    "\n",
    "training_args_2 = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "def data_collator_2(batch):\n",
    "    collated_batch = {}\n",
    "    for key in batch[0]:\n",
    "        values = [item[key] for item in batch]\n",
    "        \n",
    "        if not isinstance(values[0], torch.Tensor):\n",
    "            values = [torch.tensor(v) for v in values]\n",
    "        \n",
    "        collated_batch[key] = torch.stack(values)\n",
    "    return collated_batch\n",
    "\n",
    "# train in stages\n",
    "def curriculum_learning_train(trainer, phases):\n",
    "    for i, phase in enumerate(phases, 1):\n",
    "        print(f\"Starting Phase {i} with {len(phase['dataset'])} examples for {phase['num_epochs']} epochs.\")\n",
    "        trainer.train_dataset = phase['dataset']\n",
    "        trainer.args.num_train_epochs = phase['num_epochs']\n",
    "        trainer.train()\n",
    "\n",
    "\n",
    "def compute_metrics_2(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer_2 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_2,\n",
    "    train_dataset=easy_dataset, \n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    data_collator=data_collator_2,\n",
    "    compute_metrics=compute_metrics_2\n",
    ")\n",
    "\n",
    "phases = [\n",
    "    {\"dataset\": easy_dataset, \"num_epochs\": 2}, # easy examples for 2 epochs\n",
    "    {\"dataset\": ambiguous_dataset, \"num_epochs\": 2}, # ambiguous examples for 2 epochs\n",
    "    {\"dataset\": hard_dataset, \"num_epochs\": 3} # hard examples for 3 epochs\n",
    "]\n",
    "\n",
    "curriculum_learning_train(trainer_2, phases)\n",
    "\n",
    "results_2 = trainer_2.evaluate()\n",
    "\n",
    "print(f\"Final Accuracy on the Validation Set: {results_2['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd9226e893424fbac6a1ac2e0b97bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on the Test Set: 0.8196\n"
     ]
    }
   ],
   "source": [
    "test_dataset = encoded_dataset[\"test\"]\n",
    "\n",
    "test_results_3 = trainer_2.evaluate(eval_dataset=test_dataset)\n",
    "print(f\"Final Accuracy on the Test Set: {test_results_3['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples from the easy subset:\n",
      "Example 1: {'premise': 'A person walks on an empty sidewalk wearing a heavy coat.', 'hypothesis': 'A crowd of people walk on the sidewalk.', 'labels': 2, 'input_ids': [101, 1037, 2711, 7365, 2006, 2019, 4064, 11996, 4147, 1037, 3082, 5435, 1012, 102, 1037, 4306, 1997, 2111, 3328, 2006, 1996, 11996, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 2: {'premise': 'A male with a hat is juggling four balls.', 'hypothesis': 'A man dressed up with a hat performs a juggling act for his audience.', 'labels': 1, 'input_ids': [101, 1037, 3287, 2007, 1037, 6045, 2003, 26536, 18483, 2176, 7395, 1012, 102, 1037, 2158, 5102, 2039, 2007, 1037, 6045, 10438, 1037, 26536, 18483, 2552, 2005, 2010, 4378, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 3: {'premise': 'A girl doing a split handstand on the beach during the day with a amusement park in the background.', 'hypothesis': 'A girl doing a split handstand on the beach on a family outing.', 'labels': 1, 'input_ids': [101, 1037, 2611, 2725, 1037, 3975, 2398, 5794, 2094, 2006, 1996, 3509, 2076, 1996, 2154, 2007, 1037, 9778, 2380, 1999, 1996, 4281, 1012, 102, 1037, 2611, 2725, 1037, 3975, 2398, 5794, 2094, 2006, 1996, 3509, 2006, 1037, 2155, 26256, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "\n",
      "Examples from the ambiguous subset:\n",
      "Example 1: {'premise': 'A male wearing blue overalls, and a blue hat, rides a small house drawn carriage.', 'hypothesis': 'The carriage is being pulled by a horse.', 'labels': 1, 'input_ids': [101, 1037, 3287, 4147, 2630, 3452, 2015, 1010, 1998, 1037, 2630, 6045, 1010, 12271, 1037, 2235, 2160, 4567, 9118, 1012, 102, 1996, 9118, 2003, 2108, 2766, 2011, 1037, 3586, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 2: {'premise': 'A person wearing yellow headphones shoots a gun at a target.', 'hypothesis': 'A person is crouching below a table as the shooter takes aim.', 'labels': 2, 'input_ids': [101, 1037, 2711, 4147, 3756, 2132, 19093, 11758, 1037, 3282, 2012, 1037, 4539, 1012, 102, 1037, 2711, 2003, 21676, 2075, 2917, 1037, 2795, 2004, 1996, 13108, 3138, 6614, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 3: {'premise': \"Cute girl at a children's beauty shop sitting on a toy car having her hair blow-dried, while stylist is smiling and gentleman's arm is touching the car.\", 'hypothesis': 'The man touches the car', 'labels': 0, 'input_ids': [101, 10140, 2611, 2012, 1037, 2336, 1005, 1055, 5053, 4497, 3564, 2006, 1037, 9121, 2482, 2383, 2014, 2606, 6271, 1011, 9550, 1010, 2096, 2358, 8516, 2923, 2003, 5629, 1998, 10170, 1005, 1055, 2849, 2003, 7244, 1996, 2482, 1012, 102, 1996, 2158, 12817, 1996, 2482, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "\n",
      "Examples from the hard subset:\n",
      "Example 1: {'premise': 'The bus is gleaming', 'hypothesis': 'Light is hitting the bus.', 'labels': 0, 'input_ids': [101, 1996, 3902, 2003, 18242, 102, 2422, 2003, 7294, 1996, 3902, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 2: {'premise': 'Two little children are walking up some steps to get into an airplane.', 'hypothesis': 'An airplane is flying.', 'labels': 2, 'input_ids': [101, 2048, 2210, 2336, 2024, 3788, 2039, 2070, 4084, 2000, 2131, 2046, 2019, 13297, 1012, 102, 2019, 13297, 2003, 3909, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Example 3: {'premise': 'A group of people in front of a \"canal\" listening to live music.', 'hypothesis': 'People are listening to pre-recorded music.', 'labels': 2, 'input_ids': [101, 1037, 2177, 1997, 2111, 1999, 2392, 1997, 1037, 1000, 5033, 1000, 5962, 2000, 2444, 2189, 1012, 102, 2111, 2024, 5962, 2000, 3653, 1011, 2680, 2189, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "easy_indices = [int(i) for i in easy_indices]\n",
    "ambiguous_indices = [int(i) for i in ambiguous_indices]\n",
    "hard_indices = [int(i) for i in hard_indices]\n",
    "\n",
    "easy_dataset = Subset(encoded_dataset[\"train\"], easy_indices)\n",
    "ambiguous_dataset = Subset(encoded_dataset[\"train\"], ambiguous_indices)\n",
    "hard_dataset = Subset(encoded_dataset[\"train\"], hard_indices)\n",
    "\n",
    "def view_examples(dataset, num_examples=3):\n",
    "    sampled_indices = random.sample(range(len(dataset)), num_examples)\n",
    "    for i, idx in enumerate(sampled_indices, 1):\n",
    "        example = dataset[idx]\n",
    "        print(f\"Example {i}: {example}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Examples from the easy subset:\")\n",
    "view_examples(easy_dataset)\n",
    "\n",
    "print(\"Examples from the ambiguous subset:\")\n",
    "view_examples(ambiguous_dataset)\n",
    "\n",
    "print(\"Examples from the hard subset:\")\n",
    "view_examples(hard_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
