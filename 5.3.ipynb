{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moni/NLP/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(64, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (embeddings_project): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "              (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "              (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "              (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=64, out_features=256, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=256, out_features=64, bias=True)\n",
      "            (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd8e80eb43c4c9da417ae344074378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moni/NLP/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44393d7121bb43918cfe0f720a342be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0897, 'grad_norm': 0.929936408996582, 'learning_rate': 4.97576462604818e-05, 'epoch': 0.01}\n",
      "{'loss': 1.0378, 'grad_norm': 2.1871800422668457, 'learning_rate': 4.9515292520963604e-05, 'epoch': 0.03}\n",
      "{'loss': 1.0109, 'grad_norm': 4.704246520996094, 'learning_rate': 4.92729387814454e-05, 'epoch': 0.04}\n",
      "{'loss': 0.9949, 'grad_norm': 6.175472259521484, 'learning_rate': 4.90305850419272e-05, 'epoch': 0.06}\n",
      "{'loss': 0.9745, 'grad_norm': 11.171287536621094, 'learning_rate': 4.8788231302409e-05, 'epoch': 0.07}\n",
      "{'loss': 0.9751, 'grad_norm': 7.448033332824707, 'learning_rate': 4.8545877562890794e-05, 'epoch': 0.09}\n",
      "{'loss': 0.9606, 'grad_norm': 3.906587600708008, 'learning_rate': 4.83035238233726e-05, 'epoch': 0.1}\n",
      "{'loss': 0.9662, 'grad_norm': 9.827710151672363, 'learning_rate': 4.8061170083854396e-05, 'epoch': 0.12}\n",
      "{'loss': 0.9336, 'grad_norm': 5.347815036773682, 'learning_rate': 4.78188163443362e-05, 'epoch': 0.13}\n",
      "{'loss': 0.9208, 'grad_norm': 5.368433475494385, 'learning_rate': 4.7576462604818e-05, 'epoch': 0.15}\n",
      "{'loss': 0.9044, 'grad_norm': 5.726235389709473, 'learning_rate': 4.7334108865299795e-05, 'epoch': 0.16}\n",
      "{'loss': 0.8998, 'grad_norm': 6.098186016082764, 'learning_rate': 4.709175512578159e-05, 'epoch': 0.17}\n",
      "{'loss': 0.8835, 'grad_norm': 8.210460662841797, 'learning_rate': 4.684940138626339e-05, 'epoch': 0.19}\n",
      "{'loss': 0.883, 'grad_norm': 4.11527681350708, 'learning_rate': 4.660704764674519e-05, 'epoch': 0.2}\n",
      "{'loss': 0.8782, 'grad_norm': 11.885950088500977, 'learning_rate': 4.636469390722699e-05, 'epoch': 0.22}\n",
      "{'loss': 0.867, 'grad_norm': 4.5925703048706055, 'learning_rate': 4.612234016770879e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8689, 'grad_norm': 5.1053338050842285, 'learning_rate': 4.5879986428190594e-05, 'epoch': 0.25}\n",
      "{'loss': 0.8584, 'grad_norm': 5.482240200042725, 'learning_rate': 4.5637632688672385e-05, 'epoch': 0.26}\n",
      "{'loss': 0.8597, 'grad_norm': 8.31889820098877, 'learning_rate': 4.539527894915418e-05, 'epoch': 0.28}\n",
      "{'loss': 0.851, 'grad_norm': 4.299427032470703, 'learning_rate': 4.515292520963599e-05, 'epoch': 0.29}\n",
      "{'loss': 0.854, 'grad_norm': 6.067476749420166, 'learning_rate': 4.4910571470117784e-05, 'epoch': 0.31}\n",
      "{'loss': 0.8538, 'grad_norm': 5.1452717781066895, 'learning_rate': 4.466821773059959e-05, 'epoch': 0.32}\n",
      "{'loss': 0.8543, 'grad_norm': 8.196064949035645, 'learning_rate': 4.4425863991081386e-05, 'epoch': 0.33}\n",
      "{'loss': 0.8335, 'grad_norm': 8.218441009521484, 'learning_rate': 4.4183510251563183e-05, 'epoch': 0.35}\n",
      "{'loss': 0.8316, 'grad_norm': 7.522487163543701, 'learning_rate': 4.394115651204498e-05, 'epoch': 0.36}\n",
      "{'loss': 0.8296, 'grad_norm': 4.893707275390625, 'learning_rate': 4.369880277252678e-05, 'epoch': 0.38}\n",
      "{'loss': 0.841, 'grad_norm': 5.88109827041626, 'learning_rate': 4.345644903300858e-05, 'epoch': 0.39}\n",
      "{'loss': 0.8452, 'grad_norm': 4.74006462097168, 'learning_rate': 4.321409529349038e-05, 'epoch': 0.41}\n",
      "{'loss': 0.8219, 'grad_norm': 7.091073036193848, 'learning_rate': 4.297174155397218e-05, 'epoch': 0.42}\n",
      "{'loss': 0.8196, 'grad_norm': 5.648507595062256, 'learning_rate': 4.272938781445398e-05, 'epoch': 0.44}\n",
      "{'loss': 0.8219, 'grad_norm': 7.063343524932861, 'learning_rate': 4.248703407493578e-05, 'epoch': 0.45}\n",
      "{'loss': 0.8203, 'grad_norm': 7.2116780281066895, 'learning_rate': 4.224468033541758e-05, 'epoch': 0.47}\n",
      "{'loss': 0.815, 'grad_norm': 7.047886848449707, 'learning_rate': 4.2002326595899375e-05, 'epoch': 0.48}\n",
      "{'loss': 0.823, 'grad_norm': 8.685404777526855, 'learning_rate': 4.175997285638117e-05, 'epoch': 0.49}\n",
      "{'loss': 0.8123, 'grad_norm': 8.522465705871582, 'learning_rate': 4.1517619116862977e-05, 'epoch': 0.51}\n",
      "{'loss': 0.8057, 'grad_norm': 9.041936874389648, 'learning_rate': 4.1275265377344774e-05, 'epoch': 0.52}\n",
      "{'loss': 0.8202, 'grad_norm': 9.812054634094238, 'learning_rate': 4.103291163782657e-05, 'epoch': 0.54}\n",
      "{'loss': 0.8159, 'grad_norm': 9.462061882019043, 'learning_rate': 4.0790557898308376e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7939, 'grad_norm': 5.659982204437256, 'learning_rate': 4.054820415879017e-05, 'epoch': 0.57}\n",
      "{'loss': 0.8065, 'grad_norm': 6.406281471252441, 'learning_rate': 4.030585041927197e-05, 'epoch': 0.58}\n",
      "{'loss': 0.8065, 'grad_norm': 6.950119972229004, 'learning_rate': 4.006349667975377e-05, 'epoch': 0.6}\n",
      "{'loss': 0.8034, 'grad_norm': 4.8749260902404785, 'learning_rate': 3.9821142940235566e-05, 'epoch': 0.61}\n",
      "{'loss': 0.794, 'grad_norm': 11.194308280944824, 'learning_rate': 3.957878920071737e-05, 'epoch': 0.63}\n",
      "{'loss': 0.7967, 'grad_norm': 2.9624335765838623, 'learning_rate': 3.933643546119917e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7964, 'grad_norm': 5.350142955780029, 'learning_rate': 3.909408172168097e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7895, 'grad_norm': 6.925368309020996, 'learning_rate': 3.885172798216277e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8023, 'grad_norm': 6.74085807800293, 'learning_rate': 3.860937424264457e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7938, 'grad_norm': 10.80775260925293, 'learning_rate': 3.8367020503126365e-05, 'epoch': 0.7}\n",
      "{'loss': 0.798, 'grad_norm': 2.7153666019439697, 'learning_rate': 3.812466676360816e-05, 'epoch': 0.71}\n",
      "{'loss': 0.7806, 'grad_norm': 7.0227508544921875, 'learning_rate': 3.7882313024089966e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7966, 'grad_norm': 8.861907958984375, 'learning_rate': 3.7639959284571764e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7987, 'grad_norm': 7.652158737182617, 'learning_rate': 3.739760554505356e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7811, 'grad_norm': 8.807503700256348, 'learning_rate': 3.7155251805535366e-05, 'epoch': 0.77}\n",
      "{'loss': 0.7955, 'grad_norm': 5.4912896156311035, 'learning_rate': 3.6912898066017156e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7801, 'grad_norm': 5.720691680908203, 'learning_rate': 3.667054432649896e-05, 'epoch': 0.8}\n",
      "{'loss': 0.7929, 'grad_norm': 4.85360860824585, 'learning_rate': 3.642819058698076e-05, 'epoch': 0.81}\n",
      "{'loss': 0.7806, 'grad_norm': 4.934213161468506, 'learning_rate': 3.6185836847462556e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7926, 'grad_norm': 4.909972667694092, 'learning_rate': 3.594348310794436e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7788, 'grad_norm': 7.152347087860107, 'learning_rate': 3.570112936842616e-05, 'epoch': 0.86}\n",
      "{'loss': 0.776, 'grad_norm': 7.068304061889648, 'learning_rate': 3.5458775628907955e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7725, 'grad_norm': 13.610509872436523, 'learning_rate': 3.521642188938975e-05, 'epoch': 0.89}\n",
      "{'loss': 0.7784, 'grad_norm': 6.6584248542785645, 'learning_rate': 3.497406814987155e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7843, 'grad_norm': 4.425070285797119, 'learning_rate': 3.4731714410353354e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7786, 'grad_norm': 4.336761474609375, 'learning_rate': 3.448936067083515e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7972, 'grad_norm': 6.989936351776123, 'learning_rate': 3.424700693131695e-05, 'epoch': 0.95}\n",
      "{'loss': 0.7832, 'grad_norm': 5.990972518920898, 'learning_rate': 3.4004653191798754e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7699, 'grad_norm': 3.4452056884765625, 'learning_rate': 3.376229945228055e-05, 'epoch': 0.97}\n",
      "{'loss': 0.7597, 'grad_norm': 10.586342811584473, 'learning_rate': 3.351994571276235e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268028a8ca09412fb5e11ca48d8fa07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7322214841842651, 'eval_runtime': 6976.6707, 'eval_samples_per_second': 78.856, 'eval_steps_per_second': 9.857, 'epoch': 1.0}\n",
      "{'loss': 0.7686, 'grad_norm': 7.144468307495117, 'learning_rate': 3.3277591973244146e-05, 'epoch': 1.0}\n",
      "{'loss': 0.7512, 'grad_norm': 5.24981689453125, 'learning_rate': 3.3035238233725944e-05, 'epoch': 1.02}\n",
      "{'loss': 0.7625, 'grad_norm': 3.674412250518799, 'learning_rate': 3.279288449420775e-05, 'epoch': 1.03}\n",
      "{'loss': 0.7627, 'grad_norm': 10.069609642028809, 'learning_rate': 3.2550530754689546e-05, 'epoch': 1.05}\n",
      "{'loss': 0.756, 'grad_norm': 10.032224655151367, 'learning_rate': 3.230817701517135e-05, 'epoch': 1.06}\n",
      "{'loss': 0.7584, 'grad_norm': 7.1385817527771, 'learning_rate': 3.206582327565315e-05, 'epoch': 1.08}\n",
      "{'loss': 0.746, 'grad_norm': 6.116687297821045, 'learning_rate': 3.1823469536134945e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7562, 'grad_norm': 6.517622947692871, 'learning_rate': 3.158111579661674e-05, 'epoch': 1.11}\n",
      "{'loss': 0.7554, 'grad_norm': 11.351607322692871, 'learning_rate': 3.133876205709854e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7493, 'grad_norm': 5.642841815948486, 'learning_rate': 3.1096408317580344e-05, 'epoch': 1.13}\n",
      "{'loss': 0.7392, 'grad_norm': 7.859856605529785, 'learning_rate': 3.085405457806214e-05, 'epoch': 1.15}\n",
      "{'loss': 0.7495, 'grad_norm': 8.041143417358398, 'learning_rate': 3.061170083854394e-05, 'epoch': 1.16}\n",
      "{'loss': 0.7534, 'grad_norm': 7.803884029388428, 'learning_rate': 3.036934709902574e-05, 'epoch': 1.18}\n",
      "{'loss': 0.7457, 'grad_norm': 7.898451328277588, 'learning_rate': 3.0126993359507538e-05, 'epoch': 1.19}\n",
      "{'loss': 0.7415, 'grad_norm': 6.035031318664551, 'learning_rate': 2.9884639619989335e-05, 'epoch': 1.21}\n",
      "{'loss': 0.7604, 'grad_norm': 28.451948165893555, 'learning_rate': 2.9642285880471136e-05, 'epoch': 1.22}\n",
      "{'loss': 0.7385, 'grad_norm': 4.836870193481445, 'learning_rate': 2.9399932140952934e-05, 'epoch': 1.24}\n",
      "{'loss': 0.7441, 'grad_norm': 6.127110958099365, 'learning_rate': 2.9157578401434738e-05, 'epoch': 1.25}\n",
      "{'loss': 0.7413, 'grad_norm': 10.259288787841797, 'learning_rate': 2.8915224661916536e-05, 'epoch': 1.27}\n",
      "{'loss': 0.745, 'grad_norm': 11.382081985473633, 'learning_rate': 2.8672870922398333e-05, 'epoch': 1.28}\n",
      "{'loss': 0.7465, 'grad_norm': 8.194989204406738, 'learning_rate': 2.8430517182880134e-05, 'epoch': 1.29}\n",
      "{'loss': 0.7499, 'grad_norm': 6.3077263832092285, 'learning_rate': 2.818816344336193e-05, 'epoch': 1.31}\n",
      "{'loss': 0.7256, 'grad_norm': 6.793385982513428, 'learning_rate': 2.7945809703843732e-05, 'epoch': 1.32}\n",
      "{'loss': 0.7302, 'grad_norm': 5.580242156982422, 'learning_rate': 2.770345596432553e-05, 'epoch': 1.34}\n",
      "{'loss': 0.73, 'grad_norm': 8.967106819152832, 'learning_rate': 2.7461102224807327e-05, 'epoch': 1.35}\n",
      "{'loss': 0.7301, 'grad_norm': 6.815826416015625, 'learning_rate': 2.7218748485289132e-05, 'epoch': 1.37}\n",
      "{'loss': 0.7431, 'grad_norm': 7.372622489929199, 'learning_rate': 2.697639474577093e-05, 'epoch': 1.38}\n",
      "{'loss': 0.7383, 'grad_norm': 7.8863630294799805, 'learning_rate': 2.673404100625273e-05, 'epoch': 1.4}\n",
      "{'loss': 0.739, 'grad_norm': 4.542809963226318, 'learning_rate': 2.6491687266734528e-05, 'epoch': 1.41}\n",
      "{'loss': 0.7401, 'grad_norm': 5.852270603179932, 'learning_rate': 2.6249333527216325e-05, 'epoch': 1.43}\n",
      "{'loss': 0.7253, 'grad_norm': 9.682512283325195, 'learning_rate': 2.6006979787698126e-05, 'epoch': 1.44}\n",
      "{'loss': 0.7368, 'grad_norm': 9.650691986083984, 'learning_rate': 2.5764626048179924e-05, 'epoch': 1.45}\n",
      "{'loss': 0.732, 'grad_norm': 8.411816596984863, 'learning_rate': 2.5522272308661728e-05, 'epoch': 1.47}\n",
      "{'loss': 0.7253, 'grad_norm': 7.8695173263549805, 'learning_rate': 2.5279918569143522e-05, 'epoch': 1.48}\n",
      "{'loss': 0.7277, 'grad_norm': 6.775439262390137, 'learning_rate': 2.503756482962532e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7235, 'grad_norm': 6.675928115844727, 'learning_rate': 2.479521109010712e-05, 'epoch': 1.51}\n",
      "{'loss': 0.721, 'grad_norm': 7.1349196434021, 'learning_rate': 2.455285735058892e-05, 'epoch': 1.53}\n",
      "{'loss': 0.7338, 'grad_norm': 5.262942314147949, 'learning_rate': 2.431050361107072e-05, 'epoch': 1.54}\n",
      "{'loss': 0.7283, 'grad_norm': 7.068026542663574, 'learning_rate': 2.406814987155252e-05, 'epoch': 1.56}\n",
      "{'loss': 0.7329, 'grad_norm': 4.949480056762695, 'learning_rate': 2.382579613203432e-05, 'epoch': 1.57}\n",
      "{'loss': 0.7241, 'grad_norm': 4.766933441162109, 'learning_rate': 2.3583442392516118e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7297, 'grad_norm': 4.596033573150635, 'learning_rate': 2.3341088652997916e-05, 'epoch': 1.6}\n",
      "{'loss': 0.7205, 'grad_norm': 6.495748043060303, 'learning_rate': 2.3098734913479717e-05, 'epoch': 1.61}\n",
      "{'loss': 0.7303, 'grad_norm': 9.980240821838379, 'learning_rate': 2.2856381173961518e-05, 'epoch': 1.63}\n",
      "{'loss': 0.7285, 'grad_norm': 9.765639305114746, 'learning_rate': 2.2614027434443315e-05, 'epoch': 1.64}\n",
      "{'loss': 0.7297, 'grad_norm': 8.85857105255127, 'learning_rate': 2.2371673694925113e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7442, 'grad_norm': 4.710790157318115, 'learning_rate': 2.2129319955406913e-05, 'epoch': 1.67}\n",
      "{'loss': 0.7256, 'grad_norm': 15.329395294189453, 'learning_rate': 2.1886966215888714e-05, 'epoch': 1.69}\n",
      "{'loss': 0.728, 'grad_norm': 6.765204429626465, 'learning_rate': 2.1644612476370512e-05, 'epoch': 1.7}\n",
      "{'loss': 0.7421, 'grad_norm': 9.39671516418457, 'learning_rate': 2.140225873685231e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7254, 'grad_norm': 8.432730674743652, 'learning_rate': 2.115990499733411e-05, 'epoch': 1.73}\n",
      "{'loss': 0.717, 'grad_norm': 3.940762519836426, 'learning_rate': 2.0917551257815908e-05, 'epoch': 1.74}\n",
      "{'loss': 0.7232, 'grad_norm': 9.493598937988281, 'learning_rate': 2.067519751829771e-05, 'epoch': 1.76}\n",
      "{'loss': 0.7254, 'grad_norm': 6.4804511070251465, 'learning_rate': 2.0432843778779506e-05, 'epoch': 1.77}\n",
      "{'loss': 0.7121, 'grad_norm': 10.130692481994629, 'learning_rate': 2.0190490039261307e-05, 'epoch': 1.79}\n",
      "{'loss': 0.7304, 'grad_norm': 5.827981472015381, 'learning_rate': 1.9948136299743105e-05, 'epoch': 1.8}\n",
      "{'loss': 0.7208, 'grad_norm': 7.768207550048828, 'learning_rate': 1.9705782560224906e-05, 'epoch': 1.82}\n",
      "{'loss': 0.7097, 'grad_norm': 7.523157119750977, 'learning_rate': 1.9463428820706706e-05, 'epoch': 1.83}\n",
      "{'loss': 0.7126, 'grad_norm': 4.424004077911377, 'learning_rate': 1.9221075081188504e-05, 'epoch': 1.85}\n",
      "{'loss': 0.7201, 'grad_norm': 8.1461820602417, 'learning_rate': 1.89787213416703e-05, 'epoch': 1.86}\n",
      "{'loss': 0.7206, 'grad_norm': 6.576751232147217, 'learning_rate': 1.8736367602152102e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7149, 'grad_norm': 6.07327938079834, 'learning_rate': 1.8494013862633903e-05, 'epoch': 1.89}\n",
      "{'loss': 0.7035, 'grad_norm': 12.485450744628906, 'learning_rate': 1.82516601231157e-05, 'epoch': 1.9}\n",
      "{'loss': 0.7143, 'grad_norm': 8.988282203674316, 'learning_rate': 1.80093063835975e-05, 'epoch': 1.92}\n",
      "{'loss': 0.7104, 'grad_norm': 11.110161781311035, 'learning_rate': 1.77669526440793e-05, 'epoch': 1.93}\n",
      "{'loss': 0.7106, 'grad_norm': 5.45390510559082, 'learning_rate': 1.75245989045611e-05, 'epoch': 1.95}\n",
      "{'loss': 0.7047, 'grad_norm': 10.360118865966797, 'learning_rate': 1.7282245165042898e-05, 'epoch': 1.96}\n",
      "{'loss': 0.7116, 'grad_norm': 11.198904991149902, 'learning_rate': 1.7039891425524695e-05, 'epoch': 1.98}\n",
      "{'loss': 0.7057, 'grad_norm': 5.432448863983154, 'learning_rate': 1.6797537686006496e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b38a7fea114dc4a7256563a450f8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6695483922958374, 'eval_runtime': 6326.6387, 'eval_samples_per_second': 86.958, 'eval_steps_per_second': 10.87, 'epoch': 2.0}\n",
      "{'loss': 0.7016, 'grad_norm': 10.1483736038208, 'learning_rate': 1.6555183946488294e-05, 'epoch': 2.01}\n",
      "{'loss': 0.7018, 'grad_norm': 8.871072769165039, 'learning_rate': 1.6312830206970095e-05, 'epoch': 2.02}\n",
      "{'loss': 0.6949, 'grad_norm': 6.341709136962891, 'learning_rate': 1.6070476467451895e-05, 'epoch': 2.04}\n",
      "{'loss': 0.6953, 'grad_norm': 7.744751453399658, 'learning_rate': 1.5828122727933693e-05, 'epoch': 2.05}\n",
      "{'loss': 0.6901, 'grad_norm': 9.605010032653809, 'learning_rate': 1.558576898841549e-05, 'epoch': 2.06}\n",
      "{'loss': 0.6817, 'grad_norm': 8.296448707580566, 'learning_rate': 1.534341524889729e-05, 'epoch': 2.08}\n",
      "{'loss': 0.6981, 'grad_norm': 9.939855575561523, 'learning_rate': 1.510106150937909e-05, 'epoch': 2.09}\n",
      "{'loss': 0.702, 'grad_norm': 8.375449180603027, 'learning_rate': 1.4858707769860888e-05, 'epoch': 2.11}\n",
      "{'loss': 0.6896, 'grad_norm': 5.995030879974365, 'learning_rate': 1.4616354030342689e-05, 'epoch': 2.12}\n",
      "{'loss': 0.6921, 'grad_norm': 6.2772722244262695, 'learning_rate': 1.4374000290824488e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6831, 'grad_norm': 8.446357727050781, 'learning_rate': 1.4131646551306287e-05, 'epoch': 2.15}\n",
      "{'loss': 0.6978, 'grad_norm': 8.444391250610352, 'learning_rate': 1.3889292811788088e-05, 'epoch': 2.17}\n",
      "{'loss': 0.6804, 'grad_norm': 7.031978607177734, 'learning_rate': 1.3646939072269884e-05, 'epoch': 2.18}\n",
      "{'loss': 0.6711, 'grad_norm': 6.576053142547607, 'learning_rate': 1.3404585332751685e-05, 'epoch': 2.2}\n",
      "{'loss': 0.6956, 'grad_norm': 6.007760524749756, 'learning_rate': 1.3162231593233484e-05, 'epoch': 2.21}\n",
      "{'loss': 0.6779, 'grad_norm': 6.234984397888184, 'learning_rate': 1.2919877853715284e-05, 'epoch': 2.22}\n",
      "{'loss': 0.6944, 'grad_norm': 14.369684219360352, 'learning_rate': 1.2677524114197081e-05, 'epoch': 2.24}\n",
      "{'loss': 0.6965, 'grad_norm': 10.770301818847656, 'learning_rate': 1.2435170374678882e-05, 'epoch': 2.25}\n",
      "{'loss': 0.6879, 'grad_norm': 4.976037502288818, 'learning_rate': 1.2192816635160681e-05, 'epoch': 2.27}\n",
      "{'loss': 0.7001, 'grad_norm': 9.297689437866211, 'learning_rate': 1.195046289564248e-05, 'epoch': 2.28}\n",
      "{'loss': 0.6803, 'grad_norm': 8.931151390075684, 'learning_rate': 1.170810915612428e-05, 'epoch': 2.3}\n",
      "{'loss': 0.6823, 'grad_norm': 6.584258556365967, 'learning_rate': 1.1465755416606079e-05, 'epoch': 2.31}\n",
      "{'loss': 0.6982, 'grad_norm': 7.0386786460876465, 'learning_rate': 1.1223401677087878e-05, 'epoch': 2.33}\n",
      "{'loss': 0.6812, 'grad_norm': 5.776656150817871, 'learning_rate': 1.0981047937569677e-05, 'epoch': 2.34}\n",
      "{'loss': 0.683, 'grad_norm': 10.258605003356934, 'learning_rate': 1.0738694198051476e-05, 'epoch': 2.36}\n",
      "{'loss': 0.6936, 'grad_norm': 7.147547245025635, 'learning_rate': 1.0496340458533276e-05, 'epoch': 2.37}\n",
      "{'loss': 0.6919, 'grad_norm': 5.576517105102539, 'learning_rate': 1.0253986719015075e-05, 'epoch': 2.38}\n",
      "{'loss': 0.6969, 'grad_norm': 10.977112770080566, 'learning_rate': 1.0011632979496874e-05, 'epoch': 2.4}\n",
      "{'loss': 0.6897, 'grad_norm': 4.350299835205078, 'learning_rate': 9.769279239978673e-06, 'epoch': 2.41}\n",
      "{'loss': 0.6923, 'grad_norm': 4.086070537567139, 'learning_rate': 9.526925500460472e-06, 'epoch': 2.43}\n",
      "{'loss': 0.6925, 'grad_norm': 7.6765336990356445, 'learning_rate': 9.284571760942272e-06, 'epoch': 2.44}\n",
      "{'loss': 0.6812, 'grad_norm': 6.89747953414917, 'learning_rate': 9.042218021424071e-06, 'epoch': 2.46}\n",
      "{'loss': 0.681, 'grad_norm': 14.084359169006348, 'learning_rate': 8.79986428190587e-06, 'epoch': 2.47}\n",
      "{'loss': 0.6872, 'grad_norm': 8.269906997680664, 'learning_rate': 8.55751054238767e-06, 'epoch': 2.49}\n",
      "{'loss': 0.6838, 'grad_norm': 5.369166374206543, 'learning_rate': 8.315156802869469e-06, 'epoch': 2.5}\n",
      "{'loss': 0.7005, 'grad_norm': 13.94658374786377, 'learning_rate': 8.072803063351268e-06, 'epoch': 2.52}\n",
      "{'loss': 0.6883, 'grad_norm': 9.432046890258789, 'learning_rate': 7.830449323833067e-06, 'epoch': 2.53}\n",
      "{'loss': 0.6762, 'grad_norm': 10.125398635864258, 'learning_rate': 7.588095584314866e-06, 'epoch': 2.54}\n",
      "{'loss': 0.6778, 'grad_norm': 8.275444984436035, 'learning_rate': 7.345741844796665e-06, 'epoch': 2.56}\n",
      "{'loss': 0.6766, 'grad_norm': 7.160689353942871, 'learning_rate': 7.103388105278465e-06, 'epoch': 2.57}\n",
      "{'loss': 0.71, 'grad_norm': 18.819990158081055, 'learning_rate': 6.861034365760265e-06, 'epoch': 2.59}\n",
      "{'loss': 0.6807, 'grad_norm': 11.975380897521973, 'learning_rate': 6.618680626242063e-06, 'epoch': 2.6}\n",
      "{'loss': 0.6771, 'grad_norm': 5.529867172241211, 'learning_rate': 6.376326886723863e-06, 'epoch': 2.62}\n",
      "{'loss': 0.6898, 'grad_norm': 7.311082363128662, 'learning_rate': 6.1339731472056615e-06, 'epoch': 2.63}\n",
      "{'loss': 0.6973, 'grad_norm': 9.365402221679688, 'learning_rate': 5.8916194076874615e-06, 'epoch': 2.65}\n",
      "{'loss': 0.6744, 'grad_norm': 7.585391521453857, 'learning_rate': 5.649265668169261e-06, 'epoch': 2.66}\n",
      "{'loss': 0.6848, 'grad_norm': 12.526028633117676, 'learning_rate': 5.406911928651059e-06, 'epoch': 2.68}\n",
      "{'loss': 0.6743, 'grad_norm': 7.1322550773620605, 'learning_rate': 5.164558189132858e-06, 'epoch': 2.69}\n",
      "{'loss': 0.6875, 'grad_norm': 8.746962547302246, 'learning_rate': 4.9222044496146575e-06, 'epoch': 2.7}\n",
      "{'loss': 0.6839, 'grad_norm': 11.558550834655762, 'learning_rate': 4.679850710096457e-06, 'epoch': 2.72}\n",
      "{'loss': 0.6929, 'grad_norm': 11.127312660217285, 'learning_rate': 4.437496970578256e-06, 'epoch': 2.73}\n",
      "{'loss': 0.6884, 'grad_norm': 5.946378231048584, 'learning_rate': 4.195143231060056e-06, 'epoch': 2.75}\n",
      "{'loss': 0.6789, 'grad_norm': 7.638736248016357, 'learning_rate': 3.952789491541855e-06, 'epoch': 2.76}\n",
      "{'loss': 0.6918, 'grad_norm': 8.163055419921875, 'learning_rate': 3.710435752023654e-06, 'epoch': 2.78}\n",
      "{'loss': 0.6675, 'grad_norm': 9.064136505126953, 'learning_rate': 3.468082012505453e-06, 'epoch': 2.79}\n",
      "{'loss': 0.673, 'grad_norm': 9.521092414855957, 'learning_rate': 3.2257282729872524e-06, 'epoch': 2.81}\n",
      "{'loss': 0.6705, 'grad_norm': 9.233572006225586, 'learning_rate': 2.9833745334690516e-06, 'epoch': 2.82}\n",
      "{'loss': 0.6816, 'grad_norm': 8.193048477172852, 'learning_rate': 2.741020793950851e-06, 'epoch': 2.84}\n",
      "{'loss': 0.6834, 'grad_norm': 5.987578392028809, 'learning_rate': 2.49866705443265e-06, 'epoch': 2.85}\n",
      "{'loss': 0.673, 'grad_norm': 11.556015014648438, 'learning_rate': 2.2563133149144493e-06, 'epoch': 2.86}\n",
      "{'loss': 0.6765, 'grad_norm': 10.031359672546387, 'learning_rate': 2.0139595753962485e-06, 'epoch': 2.88}\n",
      "{'loss': 0.6761, 'grad_norm': 5.432551383972168, 'learning_rate': 1.771605835878048e-06, 'epoch': 2.89}\n",
      "{'loss': 0.6772, 'grad_norm': 8.038848876953125, 'learning_rate': 1.529252096359847e-06, 'epoch': 2.91}\n",
      "{'loss': 0.676, 'grad_norm': 8.475822448730469, 'learning_rate': 1.2868983568416461e-06, 'epoch': 2.92}\n",
      "{'loss': 0.6679, 'grad_norm': 10.56851863861084, 'learning_rate': 1.0445446173234453e-06, 'epoch': 2.94}\n",
      "{'loss': 0.6835, 'grad_norm': 6.330146312713623, 'learning_rate': 8.021908778052445e-07, 'epoch': 2.95}\n",
      "{'loss': 0.687, 'grad_norm': 8.705077171325684, 'learning_rate': 5.598371382870439e-07, 'epoch': 2.97}\n",
      "{'loss': 0.6742, 'grad_norm': 7.953701019287109, 'learning_rate': 3.17483398768843e-07, 'epoch': 2.98}\n",
      "{'loss': 0.6851, 'grad_norm': 9.715489387512207, 'learning_rate': 7.512965925064224e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7e3ee8514042dfacb0ca1c077f7d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6456310153007507, 'eval_runtime': 4209.0155, 'eval_samples_per_second': 130.708, 'eval_steps_per_second': 16.339, 'epoch': 3.0}\n",
      "{'train_runtime': 65574.5397, 'train_samples_per_second': 25.169, 'train_steps_per_second': 1.573, 'train_loss': 0.7528186898127268, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2c560bf91e49fb9c084a78f4b6c0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135e4cfd05004f1984a00e3e9fa919d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moni/NLP/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d354ce53d8947deb86c6c95efeb5055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4936, 'grad_norm': 2.8753273487091064, 'learning_rate': 4.97576462604818e-05, 'epoch': 0.01}\n",
      "{'loss': 0.4351, 'grad_norm': 5.618480682373047, 'learning_rate': 4.9515292520963604e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4334, 'grad_norm': 3.557499885559082, 'learning_rate': 4.92729387814454e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4162, 'grad_norm': 5.431368350982666, 'learning_rate': 4.90305850419272e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4095, 'grad_norm': 4.089376449584961, 'learning_rate': 4.8788231302409e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3998, 'grad_norm': 6.50526762008667, 'learning_rate': 4.8545877562890794e-05, 'epoch': 0.09}\n",
      "{'loss': 0.409, 'grad_norm': 4.539760589599609, 'learning_rate': 4.83035238233726e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4004, 'grad_norm': 16.888830184936523, 'learning_rate': 4.8061170083854396e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3869, 'grad_norm': 6.269852638244629, 'learning_rate': 4.78188163443362e-05, 'epoch': 0.13}\n",
      "{'loss': 0.3842, 'grad_norm': 5.592806816101074, 'learning_rate': 4.7576462604818e-05, 'epoch': 0.15}\n",
      "{'loss': 0.3741, 'grad_norm': 4.898906707763672, 'learning_rate': 4.7334108865299795e-05, 'epoch': 0.16}\n",
      "{'loss': 0.3836, 'grad_norm': 1.3097206354141235, 'learning_rate': 4.709175512578159e-05, 'epoch': 0.17}\n",
      "{'loss': 0.3785, 'grad_norm': 6.017665386199951, 'learning_rate': 4.684940138626339e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3856, 'grad_norm': 8.676488876342773, 'learning_rate': 4.660704764674519e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3838, 'grad_norm': 2.990272283554077, 'learning_rate': 4.636469390722699e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3721, 'grad_norm': 10.693195343017578, 'learning_rate': 4.612234016770879e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3797, 'grad_norm': 7.377981185913086, 'learning_rate': 4.5879986428190594e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3716, 'grad_norm': 4.107373237609863, 'learning_rate': 4.5637632688672385e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3818, 'grad_norm': 5.714198589324951, 'learning_rate': 4.539527894915418e-05, 'epoch': 0.28}\n",
      "{'loss': 0.365, 'grad_norm': 2.003413438796997, 'learning_rate': 4.515292520963599e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3651, 'grad_norm': 9.085955619812012, 'learning_rate': 4.4910571470117784e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3741, 'grad_norm': 7.3934006690979, 'learning_rate': 4.466821773059959e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3696, 'grad_norm': 2.870692253112793, 'learning_rate': 4.4425863991081386e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3589, 'grad_norm': 11.451123237609863, 'learning_rate': 4.4183510251563183e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3627, 'grad_norm': 1.5233513116836548, 'learning_rate': 4.394115651204498e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3648, 'grad_norm': 4.07336950302124, 'learning_rate': 4.369880277252678e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3567, 'grad_norm': 4.0238871574401855, 'learning_rate': 4.345644903300858e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3684, 'grad_norm': 5.121356964111328, 'learning_rate': 4.321409529349038e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3616, 'grad_norm': 7.258666515350342, 'learning_rate': 4.297174155397218e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3521, 'grad_norm': 5.819268226623535, 'learning_rate': 4.272938781445398e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3541, 'grad_norm': 16.584047317504883, 'learning_rate': 4.248703407493578e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3583, 'grad_norm': 1.9770047664642334, 'learning_rate': 4.224468033541758e-05, 'epoch': 0.47}\n",
      "{'loss': 0.3622, 'grad_norm': 6.6382670402526855, 'learning_rate': 4.2002326595899375e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3635, 'grad_norm': 5.154884338378906, 'learning_rate': 4.175997285638117e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3592, 'grad_norm': 4.003021717071533, 'learning_rate': 4.1517619116862977e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3462, 'grad_norm': 6.821553707122803, 'learning_rate': 4.1275265377344774e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3639, 'grad_norm': 7.335720539093018, 'learning_rate': 4.103291163782657e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3507, 'grad_norm': 5.394176483154297, 'learning_rate': 4.0790557898308376e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3548, 'grad_norm': 11.30947208404541, 'learning_rate': 4.054820415879017e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3518, 'grad_norm': 20.445398330688477, 'learning_rate': 4.030585041927197e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3345, 'grad_norm': 2.173879384994507, 'learning_rate': 4.006349667975377e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3448, 'grad_norm': 1.4680430889129639, 'learning_rate': 3.9821142940235566e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3595, 'grad_norm': 5.004947185516357, 'learning_rate': 3.957878920071737e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3584, 'grad_norm': 1.0403331518173218, 'learning_rate': 3.933643546119917e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3534, 'grad_norm': 4.7735595703125, 'learning_rate': 3.909408172168097e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3402, 'grad_norm': 6.95745325088501, 'learning_rate': 3.885172798216277e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3531, 'grad_norm': 6.3801045417785645, 'learning_rate': 3.860937424264457e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3502, 'grad_norm': 10.19935417175293, 'learning_rate': 3.8367020503126365e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3549, 'grad_norm': 2.025604009628296, 'learning_rate': 3.812466676360816e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3491, 'grad_norm': 3.38317608833313, 'learning_rate': 3.7882313024089966e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3457, 'grad_norm': 3.030565023422241, 'learning_rate': 3.7639959284571764e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3585, 'grad_norm': 6.32331657409668, 'learning_rate': 3.739760554505356e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3461, 'grad_norm': 6.568394660949707, 'learning_rate': 3.7155251805535366e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3488, 'grad_norm': 8.605569839477539, 'learning_rate': 3.6912898066017156e-05, 'epoch': 0.79}\n",
      "{'loss': 0.336, 'grad_norm': 6.049091339111328, 'learning_rate': 3.667054432649896e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3441, 'grad_norm': 13.126989364624023, 'learning_rate': 3.642819058698076e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3409, 'grad_norm': 7.979148864746094, 'learning_rate': 3.6185836847462556e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3456, 'grad_norm': 1.818707823753357, 'learning_rate': 3.594348310794436e-05, 'epoch': 0.84}\n",
      "{'loss': 0.3458, 'grad_norm': 4.306578636169434, 'learning_rate': 3.570112936842616e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3339, 'grad_norm': 4.890036582946777, 'learning_rate': 3.5458775628907955e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3321, 'grad_norm': 1.784507155418396, 'learning_rate': 3.521642188938975e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3423, 'grad_norm': 3.6360578536987305, 'learning_rate': 3.497406814987155e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3433, 'grad_norm': 3.424541711807251, 'learning_rate': 3.4731714410353354e-05, 'epoch': 0.92}\n",
      "{'loss': 0.3422, 'grad_norm': 2.362213134765625, 'learning_rate': 3.448936067083515e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3502, 'grad_norm': 9.164422988891602, 'learning_rate': 3.424700693131695e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3495, 'grad_norm': 3.9213991165161133, 'learning_rate': 3.4004653191798754e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3335, 'grad_norm': 2.318251371383667, 'learning_rate': 3.376229945228055e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3244, 'grad_norm': 9.150070190429688, 'learning_rate': 3.351994571276235e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d620fcab1b2340cd9bd330752743dba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2930378317832947, 'eval_runtime': 1854.236, 'eval_samples_per_second': 296.7, 'eval_steps_per_second': 37.088, 'epoch': 1.0}\n",
      "{'loss': 0.3286, 'grad_norm': 9.273524284362793, 'learning_rate': 3.3277591973244146e-05, 'epoch': 1.0}\n",
      "{'loss': 0.3128, 'grad_norm': 10.432160377502441, 'learning_rate': 3.3035238233725944e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2992, 'grad_norm': 7.834573745727539, 'learning_rate': 3.279288449420775e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3198, 'grad_norm': 3.936295747756958, 'learning_rate': 3.2550530754689546e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3162, 'grad_norm': 4.256681442260742, 'learning_rate': 3.230817701517135e-05, 'epoch': 1.06}\n",
      "{'loss': 0.3081, 'grad_norm': 11.89797306060791, 'learning_rate': 3.206582327565315e-05, 'epoch': 1.08}\n",
      "{'loss': 0.313, 'grad_norm': 5.215085506439209, 'learning_rate': 3.1823469536134945e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3095, 'grad_norm': 9.46875286102295, 'learning_rate': 3.158111579661674e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3059, 'grad_norm': 22.380355834960938, 'learning_rate': 3.133876205709854e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3091, 'grad_norm': 5.419338703155518, 'learning_rate': 3.1096408317580344e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3094, 'grad_norm': 18.055822372436523, 'learning_rate': 3.085405457806214e-05, 'epoch': 1.15}\n",
      "{'loss': 0.3089, 'grad_norm': 7.6920599937438965, 'learning_rate': 3.061170083854394e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2958, 'grad_norm': 4.840566158294678, 'learning_rate': 3.036934709902574e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3031, 'grad_norm': 5.5922393798828125, 'learning_rate': 3.0126993359507538e-05, 'epoch': 1.19}\n",
      "{'loss': 0.3079, 'grad_norm': 2.711472272872925, 'learning_rate': 2.9884639619989335e-05, 'epoch': 1.21}\n",
      "{'loss': 0.3059, 'grad_norm': 9.117364883422852, 'learning_rate': 2.9642285880471136e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2992, 'grad_norm': 3.7603094577789307, 'learning_rate': 2.9399932140952934e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3088, 'grad_norm': 16.107637405395508, 'learning_rate': 2.9157578401434738e-05, 'epoch': 1.25}\n",
      "{'loss': 0.3055, 'grad_norm': 14.870234489440918, 'learning_rate': 2.8915224661916536e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3094, 'grad_norm': 10.71784782409668, 'learning_rate': 2.8672870922398333e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3021, 'grad_norm': 4.497533321380615, 'learning_rate': 2.8430517182880134e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3011, 'grad_norm': 3.346019744873047, 'learning_rate': 2.818816344336193e-05, 'epoch': 1.31}\n",
      "{'loss': 0.301, 'grad_norm': 8.341278076171875, 'learning_rate': 2.7945809703843732e-05, 'epoch': 1.32}\n",
      "{'loss': 0.2941, 'grad_norm': 3.54605770111084, 'learning_rate': 2.770345596432553e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3072, 'grad_norm': 5.148650646209717, 'learning_rate': 2.7461102224807327e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2986, 'grad_norm': 14.142759323120117, 'learning_rate': 2.7218748485289132e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3182, 'grad_norm': 9.478935241699219, 'learning_rate': 2.697639474577093e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2898, 'grad_norm': 5.083569526672363, 'learning_rate': 2.673404100625273e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2964, 'grad_norm': 2.5348732471466064, 'learning_rate': 2.6491687266734528e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2983, 'grad_norm': 5.795722484588623, 'learning_rate': 2.6249333527216325e-05, 'epoch': 1.43}\n",
      "{'loss': 0.2961, 'grad_norm': 3.7696473598480225, 'learning_rate': 2.6006979787698126e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3082, 'grad_norm': 3.1357929706573486, 'learning_rate': 2.5764626048179924e-05, 'epoch': 1.45}\n",
      "{'loss': 0.3, 'grad_norm': 6.313000202178955, 'learning_rate': 2.5522272308661728e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3112, 'grad_norm': 4.868805408477783, 'learning_rate': 2.5279918569143522e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3053, 'grad_norm': 6.458998203277588, 'learning_rate': 2.503756482962532e-05, 'epoch': 1.5}\n",
      "{'loss': 0.302, 'grad_norm': 8.633746147155762, 'learning_rate': 2.479521109010712e-05, 'epoch': 1.51}\n",
      "{'loss': 0.2919, 'grad_norm': 6.072700023651123, 'learning_rate': 2.455285735058892e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2977, 'grad_norm': 3.8898918628692627, 'learning_rate': 2.431050361107072e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3175, 'grad_norm': 7.600785255432129, 'learning_rate': 2.406814987155252e-05, 'epoch': 1.56}\n",
      "{'loss': 0.3178, 'grad_norm': 2.22767972946167, 'learning_rate': 2.382579613203432e-05, 'epoch': 1.57}\n",
      "{'loss': 0.3024, 'grad_norm': 8.844865798950195, 'learning_rate': 2.3583442392516118e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3069, 'grad_norm': 5.1437153816223145, 'learning_rate': 2.3341088652997916e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2884, 'grad_norm': 3.4660866260528564, 'learning_rate': 2.3098734913479717e-05, 'epoch': 1.61}\n",
      "{'loss': 0.3095, 'grad_norm': 3.1138482093811035, 'learning_rate': 2.2856381173961518e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2952, 'grad_norm': 4.339794158935547, 'learning_rate': 2.2614027434443315e-05, 'epoch': 1.64}\n",
      "{'loss': 0.303, 'grad_norm': 9.258069038391113, 'learning_rate': 2.2371673694925113e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3129, 'grad_norm': 2.9429521560668945, 'learning_rate': 2.2129319955406913e-05, 'epoch': 1.67}\n",
      "{'loss': 0.3105, 'grad_norm': 8.489798545837402, 'learning_rate': 2.1886966215888714e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2996, 'grad_norm': 2.051730155944824, 'learning_rate': 2.1644612476370512e-05, 'epoch': 1.7}\n",
      "{'loss': 0.3116, 'grad_norm': 22.87364959716797, 'learning_rate': 2.140225873685231e-05, 'epoch': 1.72}\n",
      "{'loss': 0.3001, 'grad_norm': 4.657973289489746, 'learning_rate': 2.115990499733411e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2948, 'grad_norm': 4.023067951202393, 'learning_rate': 2.0917551257815908e-05, 'epoch': 1.74}\n",
      "{'loss': 0.2965, 'grad_norm': 7.32794713973999, 'learning_rate': 2.067519751829771e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3031, 'grad_norm': 14.012392044067383, 'learning_rate': 2.0432843778779506e-05, 'epoch': 1.77}\n",
      "{'loss': 0.294, 'grad_norm': 7.965575695037842, 'learning_rate': 2.0190490039261307e-05, 'epoch': 1.79}\n",
      "{'loss': 0.3009, 'grad_norm': 1.258851170539856, 'learning_rate': 1.9948136299743105e-05, 'epoch': 1.8}\n",
      "{'loss': 0.2979, 'grad_norm': 6.141014575958252, 'learning_rate': 1.9705782560224906e-05, 'epoch': 1.82}\n",
      "{'loss': 0.2941, 'grad_norm': 8.416426658630371, 'learning_rate': 1.9463428820706706e-05, 'epoch': 1.83}\n",
      "{'loss': 0.2991, 'grad_norm': 7.904343128204346, 'learning_rate': 1.9221075081188504e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2987, 'grad_norm': 6.0231523513793945, 'learning_rate': 1.89787213416703e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3076, 'grad_norm': 6.84902286529541, 'learning_rate': 1.8736367602152102e-05, 'epoch': 1.88}\n",
      "{'loss': 0.292, 'grad_norm': 5.193023681640625, 'learning_rate': 1.8494013862633903e-05, 'epoch': 1.89}\n",
      "{'loss': 0.2835, 'grad_norm': 5.731760025024414, 'learning_rate': 1.82516601231157e-05, 'epoch': 1.9}\n",
      "{'loss': 0.2824, 'grad_norm': 1.8647167682647705, 'learning_rate': 1.80093063835975e-05, 'epoch': 1.92}\n",
      "{'loss': 0.2927, 'grad_norm': 8.505878448486328, 'learning_rate': 1.77669526440793e-05, 'epoch': 1.93}\n",
      "{'loss': 0.2947, 'grad_norm': 8.584068298339844, 'learning_rate': 1.75245989045611e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3068, 'grad_norm': 9.152313232421875, 'learning_rate': 1.7282245165042898e-05, 'epoch': 1.96}\n",
      "{'loss': 0.3083, 'grad_norm': 3.773050308227539, 'learning_rate': 1.7039891425524695e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2969, 'grad_norm': 4.891213417053223, 'learning_rate': 1.6797537686006496e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eccc0d65eb448c9324d9768bb0a77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2353406399488449, 'eval_runtime': 14060.4365, 'eval_samples_per_second': 39.128, 'eval_steps_per_second': 4.891, 'epoch': 2.0}\n",
      "{'loss': 0.2776, 'grad_norm': 13.653707504272461, 'learning_rate': 1.6555183946488294e-05, 'epoch': 2.01}\n",
      "{'loss': 0.2614, 'grad_norm': 5.901821136474609, 'learning_rate': 1.6312830206970095e-05, 'epoch': 2.02}\n",
      "{'loss': 0.2515, 'grad_norm': 7.043242931365967, 'learning_rate': 1.6070476467451895e-05, 'epoch': 2.04}\n",
      "{'loss': 0.2627, 'grad_norm': 9.907173156738281, 'learning_rate': 1.5828122727933693e-05, 'epoch': 2.05}\n",
      "{'loss': 0.2696, 'grad_norm': 9.449553489685059, 'learning_rate': 1.558576898841549e-05, 'epoch': 2.06}\n",
      "{'loss': 0.2645, 'grad_norm': 10.251653671264648, 'learning_rate': 1.534341524889729e-05, 'epoch': 2.08}\n",
      "{'loss': 0.2587, 'grad_norm': 6.704514980316162, 'learning_rate': 1.510106150937909e-05, 'epoch': 2.09}\n",
      "{'loss': 0.2673, 'grad_norm': 6.611218452453613, 'learning_rate': 1.4858707769860888e-05, 'epoch': 2.11}\n",
      "{'loss': 0.2657, 'grad_norm': 5.7904887199401855, 'learning_rate': 1.4616354030342689e-05, 'epoch': 2.12}\n",
      "{'loss': 0.2546, 'grad_norm': 1.7451428174972534, 'learning_rate': 1.4374000290824488e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2535, 'grad_norm': 11.678256034851074, 'learning_rate': 1.4131646551306287e-05, 'epoch': 2.15}\n",
      "{'loss': 0.2623, 'grad_norm': 16.14769744873047, 'learning_rate': 1.3889292811788088e-05, 'epoch': 2.17}\n",
      "{'loss': 0.245, 'grad_norm': 9.383989334106445, 'learning_rate': 1.3646939072269884e-05, 'epoch': 2.18}\n",
      "{'loss': 0.2585, 'grad_norm': 11.220799446105957, 'learning_rate': 1.3404585332751685e-05, 'epoch': 2.2}\n",
      "{'loss': 0.2582, 'grad_norm': 1.2285664081573486, 'learning_rate': 1.3162231593233484e-05, 'epoch': 2.21}\n",
      "{'loss': 0.2542, 'grad_norm': 7.802504062652588, 'learning_rate': 1.2919877853715284e-05, 'epoch': 2.22}\n",
      "{'loss': 0.2798, 'grad_norm': 4.132735729217529, 'learning_rate': 1.2677524114197081e-05, 'epoch': 2.24}\n",
      "{'loss': 0.2606, 'grad_norm': 21.072439193725586, 'learning_rate': 1.2435170374678882e-05, 'epoch': 2.25}\n",
      "{'loss': 0.2751, 'grad_norm': 2.833930253982544, 'learning_rate': 1.2192816635160681e-05, 'epoch': 2.27}\n",
      "{'loss': 0.27, 'grad_norm': 1.4661608934402466, 'learning_rate': 1.195046289564248e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2554, 'grad_norm': 7.897249221801758, 'learning_rate': 1.170810915612428e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2538, 'grad_norm': 6.343862533569336, 'learning_rate': 1.1465755416606079e-05, 'epoch': 2.31}\n",
      "{'loss': 0.2569, 'grad_norm': 1.284663438796997, 'learning_rate': 1.1223401677087878e-05, 'epoch': 2.33}\n",
      "{'loss': 0.2649, 'grad_norm': 0.7822036743164062, 'learning_rate': 1.0981047937569677e-05, 'epoch': 2.34}\n",
      "{'loss': 0.2701, 'grad_norm': 17.614900588989258, 'learning_rate': 1.0738694198051476e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2567, 'grad_norm': 5.981959342956543, 'learning_rate': 1.0496340458533276e-05, 'epoch': 2.37}\n",
      "{'loss': 0.2683, 'grad_norm': 4.166320323944092, 'learning_rate': 1.0253986719015075e-05, 'epoch': 2.38}\n",
      "{'loss': 0.2665, 'grad_norm': 4.136029243469238, 'learning_rate': 1.0011632979496874e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2568, 'grad_norm': 6.771887302398682, 'learning_rate': 9.769279239978673e-06, 'epoch': 2.41}\n",
      "{'loss': 0.2562, 'grad_norm': 11.798907279968262, 'learning_rate': 9.526925500460472e-06, 'epoch': 2.43}\n",
      "{'loss': 0.2647, 'grad_norm': 7.459113121032715, 'learning_rate': 9.284571760942272e-06, 'epoch': 2.44}\n",
      "{'loss': 0.2641, 'grad_norm': 8.604695320129395, 'learning_rate': 9.042218021424071e-06, 'epoch': 2.46}\n",
      "{'loss': 0.256, 'grad_norm': 7.557775974273682, 'learning_rate': 8.79986428190587e-06, 'epoch': 2.47}\n",
      "{'loss': 0.2526, 'grad_norm': 8.322196006774902, 'learning_rate': 8.55751054238767e-06, 'epoch': 2.49}\n",
      "{'loss': 0.2567, 'grad_norm': 4.105989933013916, 'learning_rate': 8.315156802869469e-06, 'epoch': 2.5}\n",
      "{'loss': 0.2588, 'grad_norm': 3.452568769454956, 'learning_rate': 8.072803063351268e-06, 'epoch': 2.52}\n",
      "{'loss': 0.2621, 'grad_norm': 5.184280872344971, 'learning_rate': 7.830449323833067e-06, 'epoch': 2.53}\n",
      "{'loss': 0.2552, 'grad_norm': 5.0762739181518555, 'learning_rate': 7.588095584314866e-06, 'epoch': 2.54}\n",
      "{'loss': 0.2656, 'grad_norm': 7.602367877960205, 'learning_rate': 7.345741844796665e-06, 'epoch': 2.56}\n",
      "{'loss': 0.2564, 'grad_norm': 3.7588601112365723, 'learning_rate': 7.103388105278465e-06, 'epoch': 2.57}\n",
      "{'loss': 0.2631, 'grad_norm': 3.835153579711914, 'learning_rate': 6.861034365760265e-06, 'epoch': 2.59}\n",
      "{'loss': 0.2565, 'grad_norm': 3.8653438091278076, 'learning_rate': 6.618680626242063e-06, 'epoch': 2.6}\n",
      "{'loss': 0.2455, 'grad_norm': 5.465065002441406, 'learning_rate': 6.376326886723863e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2705, 'grad_norm': 9.42314624786377, 'learning_rate': 6.1339731472056615e-06, 'epoch': 2.63}\n",
      "{'loss': 0.259, 'grad_norm': 5.530979633331299, 'learning_rate': 5.8916194076874615e-06, 'epoch': 2.65}\n",
      "{'loss': 0.2597, 'grad_norm': 5.810939788818359, 'learning_rate': 5.649265668169261e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2669, 'grad_norm': 8.76912784576416, 'learning_rate': 5.406911928651059e-06, 'epoch': 2.68}\n",
      "{'loss': 0.2498, 'grad_norm': 9.038901329040527, 'learning_rate': 5.164558189132858e-06, 'epoch': 2.69}\n",
      "{'loss': 0.2613, 'grad_norm': 5.895630359649658, 'learning_rate': 4.9222044496146575e-06, 'epoch': 2.7}\n",
      "{'loss': 0.2542, 'grad_norm': 12.283753395080566, 'learning_rate': 4.679850710096457e-06, 'epoch': 2.72}\n",
      "{'loss': 0.254, 'grad_norm': 4.089748382568359, 'learning_rate': 4.437496970578256e-06, 'epoch': 2.73}\n",
      "{'loss': 0.2544, 'grad_norm': 1.7995179891586304, 'learning_rate': 4.195143231060056e-06, 'epoch': 2.75}\n",
      "{'loss': 0.2561, 'grad_norm': 10.541666984558105, 'learning_rate': 3.952789491541855e-06, 'epoch': 2.76}\n",
      "{'loss': 0.2513, 'grad_norm': 2.0324816703796387, 'learning_rate': 3.710435752023654e-06, 'epoch': 2.78}\n",
      "{'loss': 0.24, 'grad_norm': 6.952111721038818, 'learning_rate': 3.468082012505453e-06, 'epoch': 2.79}\n",
      "{'loss': 0.2473, 'grad_norm': 9.76846981048584, 'learning_rate': 3.2257282729872524e-06, 'epoch': 2.81}\n",
      "{'loss': 0.2558, 'grad_norm': 6.861027717590332, 'learning_rate': 2.9833745334690516e-06, 'epoch': 2.82}\n",
      "{'loss': 0.257, 'grad_norm': 3.298171281814575, 'learning_rate': 2.741020793950851e-06, 'epoch': 2.84}\n",
      "{'loss': 0.2506, 'grad_norm': 20.396705627441406, 'learning_rate': 2.49866705443265e-06, 'epoch': 2.85}\n",
      "{'loss': 0.25, 'grad_norm': 7.71986198425293, 'learning_rate': 2.2563133149144493e-06, 'epoch': 2.86}\n",
      "{'loss': 0.2444, 'grad_norm': 16.713520050048828, 'learning_rate': 2.0139595753962485e-06, 'epoch': 2.88}\n",
      "{'loss': 0.2526, 'grad_norm': 6.819385528564453, 'learning_rate': 1.771605835878048e-06, 'epoch': 2.89}\n",
      "{'loss': 0.2735, 'grad_norm': 8.493597030639648, 'learning_rate': 1.529252096359847e-06, 'epoch': 2.91}\n",
      "{'loss': 0.2608, 'grad_norm': 10.05984115600586, 'learning_rate': 1.2868983568416461e-06, 'epoch': 2.92}\n",
      "{'loss': 0.2427, 'grad_norm': 4.750765323638916, 'learning_rate': 1.0445446173234453e-06, 'epoch': 2.94}\n",
      "{'loss': 0.2605, 'grad_norm': 9.697535514831543, 'learning_rate': 8.021908778052445e-07, 'epoch': 2.95}\n",
      "{'loss': 0.2426, 'grad_norm': 7.0289387702941895, 'learning_rate': 5.598371382870439e-07, 'epoch': 2.97}\n",
      "{'loss': 0.2617, 'grad_norm': 13.53775405883789, 'learning_rate': 3.17483398768843e-07, 'epoch': 2.98}\n",
      "{'loss': 0.2571, 'grad_norm': 4.96201753616333, 'learning_rate': 7.512965925064224e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7ba4884a234a4da7f8a02aa6f6ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20425069332122803, 'eval_runtime': 1442.6806, 'eval_samples_per_second': 381.34, 'eval_steps_per_second': 47.668, 'epoch': 3.0}\n",
      "{'train_runtime': 66631.681, 'train_samples_per_second': 24.77, 'train_steps_per_second': 1.548, 'train_loss': 0.30845974834398315, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca99025f0f5450ea867a9f9552c923d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 3.4126429557800293, 'eval_model_preparation_time': 0.0023, 'eval_accuracy': 0.4032, 'eval_runtime': 31.2216, 'eval_samples_per_second': 320.291, 'eval_steps_per_second': 40.036}\n",
      "Final Accuracy on the Test Set: 0.4032\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import ElectraConfig, ElectraForSequenceClassification, ElectraTokenizer\n",
    "\n",
    " # custom config of electra with fewer layers, heads, and a smaller hidden size\n",
    "custom_config = ElectraConfig(\n",
    "    hidden_size=64, \n",
    "    num_attention_heads=2, \n",
    "    intermediate_size=256, \n",
    "    num_hidden_layers=6,\n",
    "    max_position_embeddings=64, \n",
    "    vocab_size=30522,\n",
    "    num_labels=3 \n",
    ")\n",
    "\n",
    "small_electra_model = ElectraForSequenceClassification(custom_config)\n",
    "\n",
    "# make a tokenizer from a pre-trained electra model (same vocabulary)\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "print(small_electra_model)\n",
    "\n",
    "checkpoint_folder = \"./New Folder With Items\"\n",
    "\n",
    "bias_model = small_electra_model\n",
    "bias_tokenizer = AutoTokenizer.from_pretrained(checkpoint_folder)\n",
    "\n",
    "# load snli\n",
    "snli_dataset = load_dataset(\"snli\")\n",
    "full_train_dataset = snli_dataset[\"train\"]\n",
    "\n",
    "# tokenize training set\n",
    "def bias_tokenize_function(example):\n",
    "    return bias_tokenizer(\n",
    "        example[\"premise\"], \n",
    "        example[\"hypothesis\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=57\n",
    "    )\n",
    "\n",
    "tokenized_full_train = full_train_dataset.map(bias_tokenize_function, batched=True)\n",
    "\n",
    "# define training args\n",
    "bias_training_args = TrainingArguments(\n",
    "    output_dir=\"./bias_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16, \n",
    ")\n",
    "\n",
    "# handle non-contiguous tensors\n",
    "class ContiguousTrainer(Trainer):\n",
    "    def save_model(self, output_dir=None, **kwargs): \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if not param.is_contiguous():\n",
    "                param.data = param.data.contiguous()\n",
    "        super().save_model(output_dir, **kwargs)\n",
    "\n",
    "# trainer for bias model with contiguous saving\n",
    "bias_trainer = ContiguousTrainer(\n",
    "    model=bias_model,\n",
    "    args=bias_training_args,\n",
    "    train_dataset=tokenized_full_train,\n",
    "    eval_dataset=tokenized_full_train\n",
    ")\n",
    "\n",
    "bias_trainer.train()\n",
    "\n",
    "# get predictions on train\n",
    "bias_predictions = bias_trainer.predict(tokenized_full_train).predictions\n",
    "predicted_labels = np.argmax(bias_predictions, axis=1)\n",
    "residuals = full_train_dataset[\"label\"] - predicted_labels\n",
    "\n",
    "checkpoint_folder = \"./New Folder With Items\"\n",
    "main_model = AutoModelForSequenceClassification.from_pretrained(checkpoint_folder)\n",
    "main_tokenizer = AutoTokenizer.from_pretrained(checkpoint_folder)\n",
    "\n",
    "def main_tokenize_function(example, index):\n",
    "    tokens = main_tokenizer(\n",
    "        example[\"premise\"],\n",
    "        example[\"hypothesis\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=57\n",
    "    )\n",
    "    tokens[\"labels\"] = residuals[index]\n",
    "    return tokens\n",
    "\n",
    "# apply tokenization and residual labels for residuals dataset\n",
    "tokenized_residuals = full_train_dataset.map(main_tokenize_function, with_indices=True)\n",
    "\n",
    "tokenized_residuals.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "main_training_args = TrainingArguments(\n",
    "    output_dir=\"./main_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16, \n",
    ")\n",
    "\n",
    "test_dataset = snli_dataset[\"test\"]\n",
    "\n",
    "def test_tokenize_function(example):\n",
    "    return main_tokenizer(\n",
    "        example[\"premise\"],\n",
    "        example[\"hypothesis\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=57\n",
    "    )\n",
    "\n",
    "# apply tokenization to test set\n",
    "tokenized_test_dataset = test_dataset.map(test_tokenize_function, batched=True)\n",
    "\n",
    "tokenized_test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# define a function to compute accuracy\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# update the main_trainer with compute_metrics\n",
    "main_trainer = Trainer(\n",
    "    model=main_model,\n",
    "    args=main_training_args,\n",
    "    train_dataset=tokenized_residuals,\n",
    "    eval_dataset=tokenized_residuals,\n",
    "    compute_metrics=compute_metrics \n",
    ")\n",
    "\n",
    "# now evaluate the model on the tokenized test dataset\n",
    "test_results = main_trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "\n",
    "# print the entire test_results dictionary to check available keys\n",
    "print(\"Evaluation results:\", test_results)\n",
    "\n",
    "# access accuracy if available\n",
    "if \"eval_accuracy\" in test_results:\n",
    "    print(f\"Final accuracy on the test set: {test_results['eval_accuracy']:.4f}\")\n",
    "elif \"accuracy\" in test_results:\n",
    "    print(f\"Final accuracy on test set: {test_results['accuracy']:.4f}\")\n",
    "else:\n",
    "    print(\"Error.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
